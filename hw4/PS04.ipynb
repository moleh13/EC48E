{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to use logistic regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('csv_files/credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data = credit_data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression using WC/TA, RE/TA, EBIT/TA, ME/TL, S/TA with 50% benchmark\n",
    "X = credit_data[['WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA']]\n",
    "y = credit_data['Default']\n",
    "\n",
    "weight_for_0 = 0.5  # Weight for the non-default class\n",
    "weight_for_1 = 0.5  # Weight for the default class\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(class_weight=class_weights)\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred = logistic.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.06891403426056897\n",
      "Accuracy Score: 0.9088191330343797\n",
      "Confusion Matrix: [[600   6]\n",
      " [ 55   8]]\n"
     ]
    }
   ],
   "source": [
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_train, y_pred))\n",
    "print('Confusion Matrix:', confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeMElEQVR4nO3dd1hT5+MF8BNG2OCgAiruPVEQi3VWKtZdq4I4AK3WWStat1Ktiq3WUUVxVKmrgFatratq1YrFCbhw1FUnKA5AQALJ+/ujX/MrFZRgwiXJ+TxPnprLvcnJrZrje997r0wIIUBERERkIEykDkBERESkTSw3REREZFBYboiIiMigsNwQERGRQWG5ISIiIoPCckNEREQGheWGiIiIDArLDRERERkUlhsiIiIyKCw3REREZFBYbojotSIiIiCTydQPMzMzVKhQAYGBgbh3716+2wghsGHDBrRu3RqlSpWCtbU1GjZsiFmzZiEjI6PA99q+fTs+/PBDODo6Qi6Xo3z58ujTpw9+//33QmV98eIFFi1ahObNm8PBwQGWlpaoVasWRo0ahatXrxbp8xOR/pHx3lJE9DoREREICgrCrFmzULVqVbx48QLHjx9HREQEqlSpggsXLsDS0lK9vlKphL+/P6Kjo9GqVSv07NkT1tbWOHr0KDZv3ox69erhwIEDcHJyUm8jhMCgQYMQERGBJk2aoFevXnB2dsaDBw+wfft2nDlzBseOHUOLFi0KzJmSkoKOHTvizJkz6NKlC7y9vWFra4srV64gMjISSUlJUCgUOt1XRFRCCCKi11i3bp0AIE6dOpVn+cSJEwUAERUVlWf53LlzBQAxfvz4V15r586dwsTERHTs2DHP8vnz5wsA4vPPPxcqleqV7davXy9OnDjx2pydO3cWJiYmYuvWra/87MWLF2LcuHGv3b6wcnJyRHZ2tlZei4h0g+WGiF6roHLz66+/CgBi7ty56mWZmZmidOnSolatWiInJyff1wsKChIARGxsrHqbMmXKiDp16ojc3NwiZTx+/LgAIIYMGVKo9du0aSPatGnzyvKAgABRuXJl9fObN28KAGL+/Pli0aJFolq1asLExEQcP35cmJqaii+//PKV17h8+bIAIJYuXape9vTpUzFmzBhRsWJFIZfLRfXq1cW8efOEUqnU+LMS0Ztxzg0RFcmtW7cAAKVLl1Yvi4mJwdOnT+Hv7w8zM7N8txs4cCAA4Ndff1Vv8+TJE/j7+8PU1LRIWXbu3AkAGDBgQJG2f5N169Zh6dKlGDp0KL799lu4uLigTZs2iI6OfmXdqKgomJqaonfv3gCAzMxMtGnTBhs3bsTAgQPx3Xff4b333sPkyZMRHBysk7xExi7/v32IiP4jNTUVKSkpePHiBU6cOIGZM2fCwsICXbp0Ua+TmJgIAGjcuHGBr/PyZ5cuXcrz34YNGxY5mzZe43Xu3r2La9eu4Z133lEv8/X1xaeffooLFy6gQYMG6uVRUVFo06aNek7RwoULcf36dcTHx6NmzZoAgE8//RTly5fH/PnzMW7cOLi6uuokN5Gx4sgNERWKt7c33nnnHbi6uqJXr16wsbHBzp07UbFiRfU66enpAAA7O7sCX+flz9LS0vL893XbvIk2XuN1Pv744zzFBgB69uwJMzMzREVFqZdduHABiYmJ8PX1VS/bsmULWrVqhdKlSyMlJUX98Pb2hlKpxB9//KGTzETGjCM3RFQoYWFhqFWrFlJTU7F27Vr88ccfsLCwyLPOy3LxsuTk578FyN7e/o3bvMm/X6NUqVJFfp2CVK1a9ZVljo6OaN++PaKjo/HVV18B+GfUxszMDD179lSv99dff+HcuXOvlKOXHj58qPW8RMaO5YaICsXT0xMeHh4AgB49eqBly5bw9/fHlStXYGtrCwCoW7cuAODcuXPo0aNHvq9z7tw5AEC9evUAAHXq1AEAnD9/vsBt3uTfr9GqVas3ri+TySDyuQqGUqnMd30rK6t8l/v5+SEoKAgJCQlwc3NDdHQ02rdvD0dHR/U6KpUKH3zwASZMmJDva9SqVeuNeYlIMzwsRUQaMzU1RWhoKO7fv49ly5apl7ds2RKlSpXC5s2bCywK69evBwD1XJ2WLVuidOnS+PHHHwvc5k26du0KANi4cWOh1i9dujSePXv2yvK///5bo/ft0aMH5HI5oqKikJCQgKtXr8LPzy/POtWrV8fz58/h7e2d76NSpUoavScRvRnLDREVSdu2beHp6YnFixfjxYsXAABra2uMHz8eV65cwdSpU1/ZZteuXYiIiICPjw/effdd9TYTJ07EpUuXMHHixHxHVDZu3IiTJ08WmMXLywsdO3bEmjVrsGPHjld+rlAoMH78ePXz6tWr4/Lly3j06JF62dmzZ3Hs2LFCf34AKFWqFHx8fBAdHY3IyEjI5fJXRp/69OmD2NhY7Nu375Xtnz17htzcXI3ek4jejFcoJqLXenmF4lOnTqkPS720detW9O7dGytWrMCwYcMA/HNox9fXFz/99BNat26Njz/+GFZWVoiJicHGjRtRt25dHDx4MM8VilUqFQIDA7FhwwY0bdpUfYXipKQk7NixAydPnsSff/4JLy+vAnM+evQIHTp0wNmzZ9G1a1e0b98eNjY2+OuvvxAZGYkHDx4gOzsbwD9nVzVo0ACNGzfG4MGD8fDhQ4SHh8PJyQlpaWnq09xv3bqFqlWrYv78+XnK0b9t2rQJ/fv3h52dHdq2bas+Lf2lzMxMtGrVCufOnUNgYCDc3d2RkZGB8+fPY+vWrbh161aew1hEpAXSXmaHiEq6gi7iJ4QQSqVSVK9eXVSvXj3PBfiUSqVYt26deO+994S9vb2wtLQU9evXFzNnzhTPnz8v8L22bt0qOnToIMqUKSPMzMyEi4uL8PX1FYcPHy5U1szMTLFgwQLRrFkzYWtrK+RyuahZs6YYPXq0uHbtWp51N27cKKpVqybkcrlwc3MT+/bte+1F/AqSlpYmrKysBACxcePGfNdJT08XkydPFjVq1BByuVw4OjqKFi1aiAULFgiFQlGoz0ZEhceRGyIiIjIonHNDREREBoXlhoiIiAwKyw0REREZFJYbIiIiMigsN0RERGRQWG6IiIjIoBjdvaVUKhXu378POzs7yGQyqeMQERFRIQghkJ6ejvLly8PE5PVjM0ZXbu7fvw9XV1epYxAREVER3LlzBxUrVnztOkZXbuzs7AD8s3Ps7e0lTkNERESFkZaWBldXV/X3+OsYXbl5eSjK3t6e5YaIiEjPFGZKCScUExERkUFhuSEiIiKDwnJDREREBoXlhoiIiAwKyw0REREZFJYbIiIiMigsN0RERGRQWG6IiIjIoLDcEBERkUFhuSEiIiKDImm5+eOPP9C1a1eUL18eMpkMO3bseOM2hw8fRtOmTWFhYYEaNWogIiJC5zmJiIhIf0habjIyMtC4cWOEhYUVav2bN2+ic+fOaNeuHRISEvD555/jk08+wb59+3SclIiIiPSFpDfO/PDDD/Hhhx8Wev3w8HBUrVoV3377LQCgbt26iImJwaJFi+Dj46OrmEREREZDCIGsHOVbv46VuWmhbnKpC3p1V/DY2Fh4e3vnWebj44PPP/+8wG2ys7ORnZ2tfp6WlqareERERHpNCIFe4bE48/fTt36txFk+sJZLUzP0akJxUlISnJyc8ixzcnJCWloasrKy8t0mNDQUDg4O6oerq2txRCUiItI7WTlKrRQbqenVyE1RTJ48GcHBwernaWlpLDhERERvcHqaN6zlpm9c71jMMQQGBaJ27dr4+eefYWr6zzZW5m/eVlf0qtw4OzsjOTk5z7Lk5GTY29vDysoq320sLCxgYWFRHPGIiIgMhrXc9LWHlVQqFUJDQzFjxgyoVCrYW1vi+bMncHFxKcaU+dOrcuPl5YXdu3fnWbZ//354eXlJlIiIiIyNtibclkSZisJ9ruTkZAwYMAD79+8HAAwcOBBhYWGwtbXVZbxCk7TcPH/+HNeuXVM/v3nzJhISElCmTBlUqlQJkydPxr1797B+/XoAwLBhw7Bs2TJMmDABgwYNwu+//47o6Gjs2rVLqo9ARERGRJsTbvXV77//jn79+iEpKQnW1tZYvnw5AgICpI6Vh6Tl5vTp02jXrp36+cu5MQEBAYiIiMCDBw9w+/Zt9c+rVq2KXbt2YezYsViyZAkqVqyINWvW8DRwIiIqFoYy4fZNPCqXznfOTG5uLkaNGoWkpCTUr18f0dHRqFevngQJX08mhBBShyhOaWlpcHBwQGpqKuzt7aWOQ0REeiRTkYt6M/65cGxhJ9zqo9ddo+bs2bMIDw/Ht99+C2tr62LLpMn3t17NuSEiIiop3jTh1lD89ttv+PvvvzFkyBAAQOPGjbFixQqJU72eXl3nhoiIiIpHbm4upk6dio4dO2LkyJGIi4uTOlKhGX7lJCKiIjPkM4OKorBnE+m7u3fvom/fvoiJiQEADB48uETOrSkIyw0REeWLZwYZp927d2PgwIF4/Pgx7OzssGbNGvTp00fqWBrhYSkiIsqXsZwZVBQFnU2k76ZOnYrOnTvj8ePHaNq0KeLj4/Wu2AAcuSEiokIw5DODikLKO17rUpkyZQAAo0ePxvz58/X2Cv8sN0RE9EbGcmaQMcrIyICNjQ2Af64317x5c7Rs2VLiVG+Hh6WIiIyIEAKZitxCPoxj8qyxUigU+Pzzz+Hh4YHnz58DAGQymd4XG4AjN0RERoMThOmlGzduwNfXF6dPnwYA/PLLL+jbt6/EqbSHIzdEREaiqBOEDXXyrLH66aef0KRJE5w+fRqlS5fGzp07DarYABy5ISIySppMEDbUybPG5sWLFxg/fjzCwsIAAC1atMCPP/6ISpUqSZxM+1huiIiMECcIG58vvvhCXWwmTpyIr776Cubm5hKn0g0eliIiMmB5JxBzgrAxmzp1Kho0aIA9e/Zg3rx5BltsAI7cEBEZLE4gNm5ZWVnYvn07/P39AQDOzs44e/YsTEwMf1yD5YaIyEAVNIGYE4QN3+XLl9GnTx+cP38eZmZm6qsMG0OxAVhuiIiMwr8nEHOCsGFbv349hg8fjszMTJQrV0591WFjwnJDRGQEOIHY8GVkZGD06NFYt24dAOD999/Hxo0b4eLiInGy4mcc41NEREQG7OLFi/D09MS6detgYmKCmTNn4rfffjPKYgNw5IaIyGAJIXUCKi7Xr19HYmIiXFxcsHnzZrRt21bqSJJiuSEiMkBCCPQOj5U6BumQEEI9d6pbt25Ys2YNunbtinLlykmcTHo8LEVEZICycpRIfJAGAKjnYs+zowzM2bNn0bJlS9y5c0e9bPDgwSw2/8NyQ0Rk4LYM8+LZUQZCCIGVK1eiefPm+PPPPzFu3DipI5VIPCxFRGTg2GsMQ1paGoYOHYqoqCgAQOfOnbF8+XKJU5VMLDdERCWIEAJZOW9/mwTeasGwxMXFwdfXF9euXYOZmRlCQ0MRHBxsNBfl0xTLDRFRCcHbJVB+Dh06hI4dO0KhUKBSpUqIiorCu+++K3WsEo3lhoiohCjodglvg7da0H/vvvsuateujWrVqmHt2rVGecVhTbHcEBGVQP++XcLb4K0W9NPFixdRp04dmJqawsrKCocOHUKZMmX4/7KQeLCOiKgEenm7hLd98MtQvwghsGjRIjRp0gShoaHq5WXLluX/Sw1w5IaIShRtTajVR5wEbNyePHmCwMBA/PLLLwCACxcu5LlQHxUeyw0RlRicUEvG6s8//4Sfnx/u3LkDuVyORYsWYfjw4Sw2RcTDUkRUYuhiQq0+4iRg46FSqfDNN9+gdevWuHPnDmrUqIHjx49jxIgRLDZvgSM3RFQiaWtCrT7iJGDjcf36dcyYMQNKpRJ9+/bFypUrYWdnJ3UsvcdyQ0Ql0ssJtUSGrGbNmli2bBmEEPjkk09YarWEf3MQEREVE5VKhXnz5sHb2xuenp4AgE8++UTiVIaH5YaIClTcZy7xbCEyZMnJyRgwYAD279+P1atX48KFC7CxsZE6lkFiuSGifPHMJSLt+f3339GvXz8kJSXBysoKISEhLDY6xLOliChfUp65xLOFyFAolUp8+eWX8Pb2RlJSEurXr4/Tp08jMDBQ6mgGjSM3RPRGxX3mEs8WIkOQlpaG7t274/DhwwCAQYMGYenSpbC2tpY2mBFguSGiN+KZS0Sas7W1hY2NDWxsbBAeHo7+/ftLHclo8G8rIj1UHBN9ObmXSHO5ubnIycmBlZUVTExM8MMPPyAlJQW1a9eWOppRYbkh0jOc6EtUMt29exf+/v6oWrUqfvjhBwD/3PCybNmyEiczPpxQTKRninuiLyf3Er3Z7t274ebmhqNHj2L79u24deuW1JGMGkduiPRYcUz05eReooLl5ORg6tSpmD9/PgCgadOmiIqKQpUqVaQNZuRYboj0GCf6Eknn9u3b8PPzQ2xsLABg9OjRmD9/PiwsLCRORvxbkYxGcV9tV1c40ZdIeiqVCh07dsSlS5fg4OCAtWvXomfPnlLHov9huSGjwEm4RKRNJiYmWLJkCWbMmIHNmzejatWqUkeif+GEYjIKUl5tV1c40ZeoeN24cQP79+9XP//ggw9w7NgxFpsSiCM3ZHSK+2q7usKJvkTF56effsKgQYMAAHFxcahevTqAf0ZwqORhuSGjw0m4RFRYL168wPjx4xEWFgYA8PLygrm5ucSp6E1YOYmIiPLx119/oUWLFupiM2HCBBw5cgSVKlWSOBm9Cf/5SiWats5w4hlGRKSJyMhIDB06FOnp6ShbtizWr1+PTp06SR2LConlhkosnuFERFI5ceIE0tPT0apVK2zevBkVK1aUOhJpgOWGSixdnOHEM4yIqCBCCPUk/a+//ho1atTAp59+CjMzflXqG/4fI72grTOceIYREeVn48aN2Lx5M3bu3AkzMzPI5XKMHDlS6lhURCw3pBd4hhMR6UJGRgZGjx6NdevWAQDWrVuHIUOGSJyK3ha/LeiNpLptAScBE5EuXbx4EX369EFiYiJkMhlCQkLU17Ih/SZ5uQkLC8P8+fORlJSExo0bY+nSpfD09Cxw/cWLF2PFihW4ffs2HB0d0atXL4SGhsLS0rIYUxsPTuolIkMjhEBERARGjhyJrKwsODs7Y/PmzWjXrp3U0UhLJL3OTVRUFIKDgxESEoK4uDg0btwYPj4+ePjwYb7rb968GZMmTUJISAguXbqE77//HlFRUZgyZUoxJzceJeG2BZwETETaNHPmTAwaNAhZWVn44IMPcPbsWRYbAyMTQgip3rx58+Zo1qwZli1bBuCfu6y6urpi9OjRmDRp0ivrjxo1CpcuXcLBgwfVy8aNG4cTJ04gJiamUO+ZlpYGBwcHpKamwt7eXjsfxIBlKnJRb8Y+ANLdtoCTgIlImy5duoR3330XEydOxKRJk3gLBT2hyfe3ZIelFAoFzpw5g8mTJ6uXmZiYwNvbG7Gxsflu06JFC2zcuBEnT56Ep6cnbty4gd27d2PAgAEFvk92djays7PVz9PS0rT3IYwMJ/USkT4SQuDs2bNwc3MDANStWxc3b95EmTJlpA1GOiNZXU1JSYFSqYSTk1Oe5U5OTkhKSsp3G39/f8yaNQstW7aEubk5qlevjrZt2772sFRoaCgcHBzUD1dXV61+DkMn3bgeEdHbS0tLg7+/P9zd3XH06FH1chYbw6ZXY3GHDx/G3LlzsXz5csTFxWHbtm3YtWsXvvrqqwK3mTx5MlJTU9WPO3fuFGNi/SaEQO/w/EfRiIhKuvj4eLi7uyMyMhIymQyXLl2SOhIVE8mOMTg6OsLU1BTJycl5licnJ8PZ2TnfbaZPn44BAwbgk08+AQA0bNgQGRkZGDp0KKZOnZrvcVMLCwtYWFho/wMYgawcJRIf/HMYr56LPSf1EpFeEEJg+fLlCA4OhkKhQKVKlRAZGQkvLy+po1ExkWzkRi6Xw93dPc/kYJVKhYMHDxb4GzAzM/OVAmNq+s8XroTzoo3ClmFenNRLRCXes2fP0Lt3b4waNQoKhQLdunVDfHw8i42RkXR2aHBwMAICAuDh4QFPT08sXrwYGRkZCAoKAgAMHDgQFSpUQGhoKACga9euWLhwIZo0aYLmzZvj2rVrmD59Orp27aouOaQb7DVEpA927NiBn376Cebm5vjmm28wZswY/sPMCElabnx9ffHo0SPMmDEDSUlJcHNzw969e9WTjG/fvp1npGbatGmQyWSYNm0a7t27h3feeQddu3bFnDlzpPoIRERUggQEBODcuXPo27cvmjVrJnUckoik17mRgrFe56Yot1DIVCjhMfsAACBxlg9PAyeiEufJkyeYNm2a+sxYMlx6cZ0bKj68hQIRGaLY2Fj4+fnh9u3bSE1NxaZNm6SORCWEXp0KTkXztrdQ4O0PiKgkUalUmD9/Plq3bo3bt2+jevXqGDdunNSxqAThyI2RKcotFHj7AyIqKVJSUhAQEIDdu3cD+Gfu5qpVq4xqmgG9GcuNkeEtFIhIXyUkJKBLly64d+8eLCws8N1332HIkCH8xxe9gt9yBia/icOZCs0mEhMRlUQVK1YEANSuXRvR0dFo1KiRxImopGK5MSCcOExEhiYtLU19yMnR0RH79u1D5cqVYWtrK3EyKsk4odiAvGniMCcGE5E+OXToEGrXro0ffvhBvax+/fosNvRGHLkxUPlNHObEYCLSB0qlErNnz8asWbOgUqkQFhaGAQMG5Hv/QKL8sNwYKE4cJiJ99ODBA/Tv3x+///47ACAoKAhLly5lsSGN8NvPQAghOHGYiPTa/v370b9/fzx8+BA2NjZYsWIFBgwYIHUs0kMsNwaAE4mJSN/duHEDH374IZRKJRo2bIjo6GjUqVNH6likp1huDMB/JxJz4jAR6Ztq1aph4sSJePz4MRYtWgQrKyupI5EeY7kxMKeneaOsjZwTh4moxNuzZw9q166NatWqAQBmz57Nv7tIKzhDy8BYy3lGFBGVbDk5OZgwYQI6deoEPz8/KBQKAODfXaQ1HLkhIqJic/v2bfj5+SE2NhYA4OnpCSGExKnI0LDc6Kl/32aBZ0kRkT7YuXMnAgMD8fTpUzg4OOD777/Hxx9/LHUsMkAsN3qIZ0cRkT5RKBSYNGkSFi1aBABo1qwZIiMj1XNtiLSNc270UEG3WeBZUkRUEgkh8McffwAAPv/8c8TExLDYkE5x5EbP/fs2C7y9AhGVJEIIyGQyWFhYIDo6GufPn0f37t2ljkVGgOVGz/E2C0RU0mRnZ2P8+PEoVaoUvvrqKwD/XMeGozVUXPitqId4YgERlVTXrl2Dr68v4uLiYGJigoCAANSoUUPqWGRkOOdGzwgh0Ds8VuoYRESviI6ORtOmTREXF4eyZcti586dLDYkCZYbPZOVo0TigzQAQD0Xe04gJiLJZWVlYdiwYfD19UV6ejpatmyJhIQEdO7cWepoZKR4WEqPbRnmxQnERCQpIQS8vb3x559/QiaTYfLkyZg5cybMzPj1QtLh7z49xl5DRFKTyWQYMmQI/vrrL2zcuBEdOnSQOhIRD0sREZFmMjMzcenSJfXzwMBAXLlyhcWGSgyWGyIiKrTExER4enqiQ4cOePz4sXp56dKlJUxFlBfLDRERFUpERAQ8PDxw8eJF5Obm4tatW1JHIsoXyw0REb3W8+fPERAQgKCgIGRlZcHb2xsJCQlwd3eXOhpRvlhuiIioQOfPn0ezZs2wfv16mJiYYPbs2di3bx+cnJykjkZUIJ4tRUREBfr6669x+fJllC9fHj/++CNat24tdSSiN2K5ISKiAoWFhcHKygpz587FO++8I3UcokLhYSkiIlKLj4/HF198AfG/m9g5ODhg9erVLDakV95q5ObFixewtLTUVhYiIpKIEAIrVqzA2LFjoVAoUK9ePQQFBUkdi6hINB65UalU+Oqrr1ChQgXY2trixo0bAIDp06fj+++/13pAIiLSrdTUVPTp0wcjR46EQqFA165d0b17d6ljERWZxuVm9uzZiIiIwDfffAO5XK5e3qBBA6xZs0ar4YiISLdOnTqFJk2aYOvWrTA3N8fChQvx888/o0yZMlJHIyoyjcvN+vXrsWrVKvTr1w+mpv9/R+rGjRvj8uXLWg1HRES6s3btWrz33nu4efMmqlSpgpiYGIwdO5Y35CW9p3G5uXfvHmrUqPHKcpVKhZycHK2EIiIi3atRowaUSiV69uyJ+Ph4eHp6Sh2JSCs0nlBcr149HD16FJUrV86zfOvWrWjSpInWghERkfY9e/YMpUqVAgC0bt0aJ06cgLu7O0dryKBoXG5mzJiBgIAA3Lt3DyqVCtu2bcOVK1ewfv16/Prrr7rISEREb0mlUmHhwoWYM2cOYmNjUadOHQCAh4eHxMmItE/jw1Ldu3fHL7/8ggMHDsDGxgYzZszApUuX8Msvv+CDDz7QRUYiInoLKSkp6NatG7744gs8e/YMGzZskDoSkU4V6To3rVq1wv79+7WdhYiItCwmJgZ9+/bF3bt3YWFhgSVLlmDo0KFSxyLSKY1HbqpVq4bHjx+/svzZs2eoVq2aVkIREdHbUalUCA0NRdu2bXH37l3UqlULJ06cwKeffsr5NWTwNC43t27dglKpfGV5dnY27t27p5VQRET0diIiIjBlyhQolUr0798fZ86cQePGjaWORVQsCn1YaufOnepf79u3Dw4ODurnSqUSBw8eRJUqVbQajoiIimbgwIGIjIyEn58fgoKCOFpDRqXQ5aZHjx4AAJlMhoCAgDw/Mzc3R5UqVfDtt99qNRwRERWOUqnE999/j8DAQMjlcpiZmWHfvn0sNWSUCl1uVCoVAKBq1ao4deoUHB0ddRaKiIgKLykpCf369cPvv/+Oy5cvY+HChQDAYkNGS+OzpW7evKmLHFRIQkidgIhKkgMHDqB///5ITk6GtbU1L6ZKhCKeCp6RkYEjR47g9u3bUCgUeX722WefaSUYvUoIgd7hsVLHIKISIDc3FzNnzsScOXMghEDDhg0RHR2tvjgfkTHTuNzEx8ejU6dOyMzMREZGBsqUKYOUlBRYW1ujXLlyLDc6lJWjROKDNABAPRd7WJmbvmELIjJE9+7dg7+/P/744w8AwJAhQ7BkyRJYWVlJnIyoZND4VPCxY8eia9euePr0KaysrHD8+HH8/fffcHd3x4IFC3SRkfKxZZgXj6cTGamsrCzEx8fD1tYWmzdvxqpVq1hsiP5F45GbhIQErFy5EiYmJjA1NUV2djaqVauGb775BgEBAejZs6cuctJ/sNcQGRchhPofNDVq1EB0dDSqV6+OmjVrSpyMqOTReOTG3NwcJib/bFauXDncvn0bAODg4IA7d+5oNx0REeHOnTto06YNDhw4oF7WsWNHFhuiAmg8ctOkSROcOnUKNWvWRJs2bTBjxgykpKRgw4YNaNCggS4yEhEZrV9++QWBgYF48uQJRo4cicTERJiacr4d0etoPHIzd+5cuLi4AADmzJmD0qVLY/jw4Xj06BFWrlyp9YBERMZIoVBg3Lhx6NatG548eQIPDw/s2bOHxYaoEDQeufHw8FD/uly5cti7d69WAxERGbtbt27B19cXJ0+eBACMGTMGX3/9NSwsLCRORqQfNB65KUhcXBy6dOmi8XZhYWGoUqUKLC0t0bx5c/Uf5oI8e/YMI0eOhIuLCywsLFCrVi3s3r27qLGJiEqUO3fuoEmTJjh58iRKlSqF7du3Y/HixSw2RBrQqNzs27cP48ePx5QpU3Djxg0AwOXLl9GjRw80a9ZMfYuGwoqKikJwcDBCQkIQFxeHxo0bw8fHBw8fPsx3fYVCgQ8++AC3bt3C1q1bceXKFaxevRoVKlTQ6H2JiEqqihUromvXrnj33XeRkJCgvq8fERVeoQ9Lff/99xgyZAjKlCmDp0+fYs2aNVi4cCFGjx4NX19fXLhwAXXr1tXozRcuXIghQ4YgKCgIABAeHo5du3Zh7dq1mDRp0ivrr127Fk+ePMGff/4Jc3NzAOCdyIlI712/fh2lSpVC2bJlIZPJEB4eDnNzc/Xfc0SkmUKP3CxZsgRff/01UlJSEB0djZSUFCxfvhznz59HeHi4xsVGoVDgzJkz8Pb2/v8wJibw9vZGbGz+txjYuXMnvLy8MHLkSDg5OaFBgwaYO3culEplge+TnZ2NtLS0PA8iopIiOjoaTZo0QVBQEMT/bh5nbW3NYkP0Fgpdbq5fv47evXsDAHr27AkzMzPMnz8fFStWLNIbp6SkQKlUwsnJKc9yJycnJCUl5bvNjRs3sHXrViiVSuzevRvTp0/Ht99+i9mzZxf4PqGhoXBwcFA/XF1di5SXiEibXrx4geHDh8PX1xfp6el48uQJ//FFpCWFLjdZWVmwtrYGAMhkMlhYWKhPCS8uKpUK5cqVw6pVq+Du7g5fX19MnToV4eHhBW4zefJkpKamqh+80CARSe3q1at499131X93TZ48GYcPH4aDg4PEyYgMg0angq9Zswa2trYA/rkjbUREBBwdHfOsU9gbZzo6OsLU1BTJycl5licnJ8PZ2TnfbVxcXGBubp7nOg9169ZFUlISFAoF5HL5K9tYWFjwLAMiKjE2bdqETz/9FBkZGXjnnXewYcMG+Pj4SB2LyKAUutxUqlQJq1evVj93dnbGhg0b8qwjk8kKXW7kcjnc3d1x8OBB9dkAKpUKBw8exKhRo/Ld5r333sPmzZuhUqnUt4C4evUqXFxc8i02hkQIgUxFwXOLiKjky8zMxLRp05CRkYG2bdti06ZNKF++vNSxiAxOocvNrVu3tP7mwcHBCAgIgIeHBzw9PbF48WJkZGSoz54aOHAgKlSogNDQUADA8OHDsWzZMowZMwajR4/GX3/9hblz5xa6UOkrIQR6hcfizN9PpY5CRG/B2toaUVFR6jmDvNowkW5ofIVibfL19cWjR48wY8YMJCUlwc3NDXv37lVPMr59+7Z6hAYAXF1dsW/fPowdOxaNGjVChQoVMGbMGEycOFGqj1AssnKUeYqNR+XSsDLnX4pE+uCHH36AUqnEoEGDAACenp7w9PSUOBWRYZOJl+ceGom0tDQ4ODggNTUV9vb2UscplExFLurN2AcAOD3NG2Vt5JDJZBKnIqLXef78OUaOHIn169fDwsIC586dQ61ataSORaS3NPn+lnTkhjRnLTdlsSEq4c6fP48+ffrg8uXLMDExwbRp01C9enWpYxEZDZabEo4TiYn0hxAC33//PUaPHo0XL16gfPny2Lx5M9q0aSN1NCKjwnJTgnEiMZH+EEIgICBAfRZpx44dsX79erzzzjsSJyMyPkW6K/j169cxbdo09O3bV32Tyz179uDixYtaDWfsOJGYSH/IZDLUrFkTpqammDdvHnbt2sViQyQRjcvNkSNH0LBhQ5w4cQLbtm3D8+fPAQBnz55FSEiI1gPSP05P88aWYV6cb0NUgggh8PTp//8DZMqUKThz5gwmTpyY50xPIipeGv/pmzRpEmbPno39+/fnuXDe+++/j+PHj2s1HP0/TiQmKllSU1Ph6+uLtm3bIisrCwBgamqKxo0bS5yMiDQuN+fPn8dHH330yvJy5cohJSVFK6GIiEqy06dPo2nTptiyZQsSExNx7NgxqSMR0b9oXG5KlSqFBw8evLI8Pj4eFSpU0EooIqKSSAiB7777Di1atMCNGzdQuXJlxMTEwNvbW+poRPQvGpcbPz8/TJw4EUlJSZDJZFCpVDh27BjGjx+PgQMH6iIjEZHknj59ip49e2LMmDHIyclBjx49EB8fj+bNm0sdjYj+Q+NyM3fuXNSpUweurq54/vw56tWrh9atW6NFixaYNm2aLjISEUluxIgR2LFjB+RyOb777jts27YNpUuXljoWEeVD4+vcyOVyrF69GtOnT8eFCxfw/PlzNGnSBDVr1tRFPiKiEuHrr7/G9evXsWLFCri7u0sdh4heQ+NyExMTg5YtW6JSpUqoVKmSLjIREUnu8ePH+OWXXxAYGAgAqFSpEk6cOMGzFon0gMaHpd5//31UrVoVU6ZMQWJioi4yEXjbBSIpHTt2DG5ubggKCsIvv/yiXs5iQ6QfNC439+/fx7hx43DkyBE0aNAAbm5umD9/Pu7evauLfEbp5W0XPGYfkDoKkVFRqVSYN28e2rRpg7t376JmzZpwdXWVOhYRaUjjcuPo6IhRo0bh2LFjuH79Onr37o0ffvgBVapUwfvvv6+LjEaHt10gKn4PHz5Ep06dMHnyZCiVSvj7++PMmTNwc3OTOhoRaeitbpxZtWpVTJo0CY0bN8b06dNx5MgRbeWi/zk9zRtlbeQcDifSoSNHjqBv37548OABLC0tsWzZMgwaNIh/7oj0VJFvfnLs2DGMGDECLi4u8Pf3R4MGDbBr1y5tZiPwtgtExeHBgwd48OAB6tati1OnTmHw4MH8c0ekxzQeuZk8eTIiIyNx//59fPDBB1iyZAm6d+8Oa2trXeQzSkJInYDI8Akh1AXGz88PCoUCH3/8MWxsbCRORkRvS+ORmz/++ANffPEF7t27h19//RV9+/ZlsdEiIQR6h8dKHYPIoB08eBBNmzZFUlKSetnAgQNZbIgMhMYjN7xBnG5l5SiR+CANAFDPxZ4TiYm0SKlUYubMmZg9ezaEEJg5cyZWrFghdSwi0rJClZudO3fiww8/hLm5OXbu3Pnadbt166aVYARsGebF4/5EWnL//n34+/urT3z45JNP8O2330qcioh0oVDlpkePHkhKSkK5cuXQo0ePAteTyWRQKnnhOW1hryHSjn379qF///5ISUmBra0tVq5cCX9/f6ljEZGOFKrcqFSqfH9NRFTSbdmyBX369AEANG7cGNHR0ahVq5bEqYhIlzSeULx+/XpkZ2e/slyhUGD9+vVaCUVEpC0dO3ZErVq1MGLECBw/fpzFhsgIaFxugoKCkJqa+sry9PR0BAUFaSUUEdHbOH78OMT/rqlgZ2eHU6dOISwsDJaWlhInI6LioHG5+fe1If7t7t27cHBw0EooIqKiUCgUGD9+PLy8vLB48WL1cnt7e+lCEVGxK/Sp4E2aNIFMJoNMJkP79u1hZvb/myqVSty8eRMdO3bUSUgioje5desW/Pz8cOLECQDAvXv3JE5ERFIpdLl5eZZUQkICfHx8YGtrq/6ZXC5HlSpV8PHHH2s9IBHRm+zYsQNBQUF49uwZSpUqhXXr1r32zE4iMmyFLjchISEAgCpVqsDX15fHrolIctnZ2ZgwYQK+++47AEDz5s0RGRmJKlWqSBuMiCSl8ZybgIAAFhsiKhESExOxfPlyAMC4cePwxx9/sNgQUeFGbsqUKYOrV6/C0dERpUuXfu1Vc588eaK1cEREr9OkSRMsXboUFStWRJcuXaSOQ0QlRKHKzaJFi2BnZ6f+NW8JQERSePHiBSZOnIjBgwejUaNGAIBhw4ZJnIqISppClZuAgAD1rwMDA3WVhYioQFevXkWfPn1w9uxZ/Pbbbzh//nyeszaJiF7SeM5NXFwczp8/r37+888/o0ePHpgyZQoUCoVWwxERAcDmzZvh7u6Os2fP4p133sHixYtZbIioQBqXm08//RRXr14FANy4cQO+vr6wtrbGli1bMGHCBK0HJCLjlZmZiSFDhqBfv354/vw52rRpo74cBRFRQTQuN1evXoWbmxuAf25I16ZNG2zevBkRERH46aeftJ2PiIxUUlISmjdvjjVr1kAmk2HGjBk4cOAAypcvL3U0IirhNB7XFUKo7wx+4MAB9RkKrq6uSElJ0W46IjJa77zzDsqVKwcnJyds2rQJ7du3lzoSEekJjcuNh4cHZs+eDW9vbxw5cgQrVqwAANy8eRNOTk5aD0hExiMjIwOmpqawtLSEqakpNm3aBABwdnaWOBkR6ROND0stXrwYcXFxGDVqFKZOnYoaNWoAALZu3YoWLVpoPSARGYcLFy6gWbNmGDt2rHqZs7Mziw0RaUzjkZtGjRrlOVvqpfnz58PU1FQroYjIeAghsHbtWowaNQovXrxAamoqZs+ejbJly0odjYj0VJHPpTxz5gwuXboEAKhXrx6aNm2qtVBEZBzS09MxfPhw9eEnHx8fbNiwgcWGiN6KxuXm4cOH8PX1xZEjR1CqVCkAwLNnz9CuXTtERkbinXfe0XZGIjJAZ8+eRZ8+fXD16lWYmppi9uzZmDBhAkxMND5aTkSUh8Z/i4wePRrPnz/HxYsX8eTJEzx58gQXLlxAWloaPvvsM11kJCIDk52djU6dOuHq1auoWLEijhw5gkmTJrHYEJFWaDxys3fvXhw4cAB169ZVL6tXrx7CwsLQoUMHrYYjIsNkYWGBFStWYPXq1YiIiOBhKCLSKo3LjUqlgrm5+SvLzc3N1de/ISL6rzNnzuDp06fw9vYGAHTr1g1du3bljXiJSOs0HgN+//33MWbMGNy/f1+97N69exg7diwvskVErxBCYOnSpWjRogV8fX1x584d9c9YbIhIFzQuN8uWLUNaWhqqVKmC6tWro3r16qhatSrS0tKwdOlSXWQkIj319OlTfPzxx/jss8+gUCjQunVr2NraSh2LiAycxoelXF1dERcXh4MHD6pPBa9bt656qJmICABOnDgBPz8/3Lp1C3K5HAsWLMCoUaM4WkNEOqdRuYmKisLOnTuhUCjQvn17jB49Wle5iEhPCSGwaNEiTJw4Ebm5uahWrRqio6Ph7u4udTQiMhKFLjcrVqzAyJEjUbNmTVhZWWHbtm24fv065s+fr8t8RkMIgawcJTIVSqmjEL0VmUyGy5cvIzc3F71798bq1avh4OAgdSwiMiIyIYQozIr169dHnz59EBISAgDYuHEjPv30U2RkZOg0oLalpaXBwcEBqampsLe3lzoOgH+KTa/wWJz5+2me5YmzfGAtL/JFpImKlUqlUl+nJisrC9u2bYO/vz8PQxGRVmjy/V3oCcU3btxAQECA+rm/vz9yc3Px4MGDoiclAEBWjvKVYuNRuTSszHmvLir5VCoVvv76a3Tp0kV9OQgrKyv069ePxYaIJFHoYYHs7GzY2Nion5uYmEAulyMrK0snwYzV6WnesJabwsrclF8MVOI9evQIAwcOxN69ewEAP//8Mz766COJUxGRsdPomMf06dNhbW2tfq5QKDBnzpw8x9MXLlyovXRGyFpuykNRpBf++OMP9O3bF/fv34elpSWWLVuGHj16SB2LiKjw5aZ169a4cuVKnmUtWrTAjRs31M850kBk+JRKJUJDQxESEgKVSoW6desiOjoaDRo0kDoaEREADcrN4cOHdRiDiPTFiBEjsGrVKgBAYGAgli1blueQNRGR1ErELXjDwsJQpUoVWFpaonnz5jh58mShtouMjIRMJuNQOFExGj58OMqUKYMffvgB69atY7EhohJH8nITFRWF4OBghISEIC4uDo0bN4aPjw8ePnz42u1u3bqF8ePHo1WrVsWUlMg4KZVKxMbGqp+7ubnh77//xsCBAyVMRURUMMnLzcKFCzFkyBAEBQWhXr16CA8Ph7W1NdauXVvgNkqlEv369cPMmTNRrVq1YkxLZFzu37+P9u3bo02bNjh16pR6Oe8PRUQlmaTlRqFQ4MyZM3nuS2ViYgJvb+88/1L8r1mzZqFcuXIYPHhwccQkMkr79u2Dm5sbjhw5AgsLC9y/f1/qSEREhSLpOccpKSlQKpVwcnLKs9zJyQmXL1/Od5uYmBh8//33SEhIKNR7ZGdnIzs7W/08LS2tyHmJjEFubi6mT5+OefPmAQAaN26M6Oho1KpVS+JkRESFU6SRm6NHj6J///7w8vLCvXv3AAAbNmxATEyMVsP9V3p6OgYMGIDVq1fD0dGxUNuEhobCwcFB/XB1ddVpRiJ9dufOHbRt21ZdbEaMGIHjx4+z2BCRXtG43Pz000/w8fGBlZUV4uPj1aMiqampmDt3rkav5ejoCFNTUyQnJ+dZnpycDGdn51fWv379Om7duoWuXbvCzMwMZmZmWL9+PXbu3AkzMzNcv379lW0mT56M1NRU9ePOnTsaZSQyJtu2bcOxY8dgb2+P6OhohIWFwdLSUupYREQa0bjczJ49G+Hh4Vi9ejXMzc3Vy9977z3ExcVp9FpyuRzu7u44ePCgeplKpcLBgwfh5eX1yvp16tTB+fPnkZCQoH5069YN7dq1Q0JCQr6jMhYWFrC3t8/zIKL8jR49GhMmTEBcXBx69+4tdRwioiLReM7NlStX0Lp161eWOzg44NmzZxoHCA4ORkBAADw8PODp6YnFixcjIyMDQUFBAICBAweiQoUKCA0NhaWl5StXQS1VqhQA8OqoREXw999/Y/r06Vi+fDlsbW1hYmKCr7/+WupYRERvReNy4+zsjGvXrqFKlSp5lsfExBTptGxfX188evQIM2bMQFJSEtzc3LB37171JOPbt2/DxETyM9aJDM7PP/+MwMBAPHv2DLa2tli+fLnUkYiItELjcjNkyBCMGTMGa9euhUwmw/379xEbG4vx48dj+vTpRQoxatQojBo1Kt+fvem2DxEREUV6TyJjpVAoMGHCBCxZsgQA4OnpiQkTJkiciohIezQuN5MmTYJKpUL79u2RmZmJ1q1bw8LCAuPHj8fo0aN1kZGItOTGjRvw9fXF6dOnAQDjxo3D3LlzIZfLJU5GRKQ9GpcbmUyGqVOn4osvvsC1a9fw/Plz1KtXj1csJSrhDh8+jO7duyMtLU19b6guXbpIHYuISOuKfBE/uVyOevXqaTMLEelQ7dq1YWlpiYYNG+LHH3/kNZ+IyGBpXG7atWsHmUxW4M9///33twpERNqTkpKivuCli4sLjhw5gurVq+e5jAMRkaHR+DQkNzc3NG7cWP2oV68eFAoF4uLi0LBhQ11kJKIi+PHHH1GtWjVs3bpVvaxOnTosNkRk8DQeuVm0aFG+y7/88ks8f/78rQMR0dvJysrCmDFjsHr1agDA+vXr0atXL4lTEREVH61dQKZ///5Yu3attl6OiIrg8uXLaN68OVavXg2ZTIbp06dj27ZtUsciIipWWrsreGxsLO9BQySh9evXY/jw4cjMzISTkxM2btwIb29vqWMRERU7jctNz5498zwXQuDBgwc4ffp0kS/iR0RvJy4uDgEBAQCA999/H5s2bcr35rNERMZA43Lj4OCQ57mJiQlq166NWbNmoUOHDloLRkSF17RpU4wbNw4ODg6YMmUKTE1NpY5ERCQZjcqNUqlEUFAQGjZsiNKlS+sqExG9gRAC69evR/v27VGxYkUAwIIFCyRORURUMmg0odjU1BQdOnQo0t2/iUg70tPTMWDAAAQGBqJv377Izc2VOhIRUYmi8dlSDRo0wI0bN3SRhYje4OzZs/Dw8MCmTZtgamqKzp07w8REayc9EhEZBI3/Vpw9ezbGjx+PX3/9FQ8ePEBaWlqeBxFpnxACK1euRPPmzXH16lVUrFgRR44cwaRJk1huiIj+o9BzbmbNmoVx48ahU6dOAIBu3brluQ2DEAIymQxKpVL7KYmMWHp6Oj755BNER0cDALp06YKIiAiULVtW4mRERCVTocvNzJkzMWzYMBw6dEiXeYjoP0xNTZGYmAgzMzPMmzcPwcHBr72/GxGRsSt0uRFCAADatGmjszBE9A8hBIQQMDExgbW1NaKjo5Gamop3331X6mhERCWeRgfr+a9FIt179uwZevXqha+//lq9rG7duiw2RESFpNF1bmrVqvXGgvPkyZO3CkRkzE6ePAlfX1/cunULe/bswaBBg+Dk5CR1LCIivaJRuZk5c+YrVyimt/e/I35kxIQQWLx4MSZOnIicnBxUq1YNUVFRLDZEREWgUbnx8/NDuXLldJXFKAkh0Ds8VuoYJKEnT54gMDAQv/zyCwCgV69eWLNmDf8hQURURIUuN5xvoxtZOUokPvjn+kD1XOxhZc57AhkThUKBd999F3/99RcsLCywaNEiDBs2jH/eiIjeQqEnFAseO9G5LcO8+KVmZORyOT7//HPUrFkTx48fx/Dhw/l7gIjoLRW63KhUKh6S0jF+pxmHlJQUJCYmqp8PHz4cCQkJcHNzky4UEZEB4XXbiYrR0aNH0bhxY3Tt2hWpqakA/jnka21tLXEyIiLDwXJDVAxUKhXmzJmDtm3b4v79+5DL5Xj06JHUsYiIDJJGZ0sRkeaSk5MxYMAA7N+/HwAQEBCAsLAw2NjYSJyMiMgwsdwQ6dDvv/+Ofv36ISkpCdbW1li+fDkCAgKkjkVEZNBYboh0aNGiRUhKSkL9+vURHR2NevXqSR2JiMjgcc4NkQ6tW7cO48ePx8mTJ1lsiIiKCcuNhIQQyFQopY5BWvTbb79h/Pjx6ueOjo6YP38+z4YiIipGPCwlESEEeoXH4szfT6WOQlqQm5uLkJAQhIaGQgiBFi1aoGfPnlLHIiIySiw3EsnKUeYpNh6VS/PWC3rq7t278Pf3x9GjRwEAw4YNw4cffihxKiIi48VyUwKcnuaNsjZyXnZfD+3evRsDBw7E48ePYWdnhzVr1qBPnz5SxyIiMmqcc1MCWMtNWWz00Ny5c9G5c2c8fvwY7u7uiI+PZ7EhIioBWG6Iisjd3R0ymQyjR4/GsWPHUL16dakjEREReFiKSCMPHz5U30DWx8cHFy9eRN26dSVORURE/8aRG6JCUCgUGDt2LGrXro0bN26ol7PYEBGVPCw3RG9w8+ZNtGzZEosXL8azZ8+wZ88eqSMREdFrsNwQvcZPP/2EJk2a4NSpUyhTpgx27tyJkSNHSh2LiIheg+WGKB8vXrzAqFGj0KtXL6SmpqJFixaIj49H165dpY5GRERvwHJDlI/vvvsOYWFhAICJEyfi8OHDqFSpksSpiIioMHi2FFE+xowZg0OHDuGzzz7j1YaJiPQMR26IAGRlZWHBggXIzc0FAFhYWGDPnj0sNkREeogjN2T0Ll++jD59+uD8+fN49uwZZs+eLXUkIiJ6Cxy5IaO2YcMGeHh44Pz583ByckLbtm2ljkRERG+J5UYiQkidwLhlZGRg0KBBGDhwIDIyMvD+++8jISEB3t7eUkcjIqK3xHIjASEEeofHSh3DaF26dAmenp5Yt24dTExMMHPmTPz2229wdnaWOhoREWkB59xIICtHicQHaQCAei72sDI3lTiRcVGpVLh58yZcXFywefNmHooiIjIwLDcS2zLMCzKZTOoYBk+pVMLU9J8SWb9+fWzfvh1NmjRR3wSTiIgMBw9LSYy9RvfOnj2LRo0aISYmRr3Mx8eHxYaIyECx3EiAk4mLhxACK1euRPPmzZGYmIgvvvgCgjufiMjgsdwUM04mLh5paWno27cvhg0bhuzsbHTq1Am//PILDwESERkBlptixsnEuhcXFwd3d3dERUXBzMwM8+fPxy+//AJHR0epoxERUTHghGIJcTKx9l24cAFeXl5QKBSoVKkSIiMj4eXlJXUsIiIqRiw3EmKv0b769eujS5cuyM3Nxbp161CmTBmpIxERUTErEYelwsLCUKVKFVhaWqJ58+Y4efJkgeuuXr0arVq1QunSpVG6dGl4e3u/dn0yfKdPn0ZqaioAQCaTYePGjdixYweLDRGRkZK83ERFRSE4OBghISGIi4tD48aN4ePjg4cPH+a7/uHDh9G3b18cOnQIsbGxcHV1RYcOHXDv3r1iTl40PFlHe4QQWLRoEVq0aIGhQ4eqz4SysrLi4T4iIiMmeblZuHAhhgwZgqCgINSrVw/h4eGwtrbG2rVr811/06ZNGDFiBNzc3FCnTh2sWbMGKpUKBw8eLObkmuOZUtrz5MkT9OjRA8HBwcjJyYFKpYJCoZA6FhERlQCSlhuFQoEzZ87kuVmhiYkJvL29ERtbuBKQmZmJnJwcvTgEwTOltCM2NhZubm7YuXMn5HI5wsLCEB0dDQsLC6mjERFRCSDphOKUlBQolUo4OTnlWe7k5ITLly8X6jUmTpyI8uXLF3g35+zsbGRnZ6ufp6WlFT2wFvFMKc2pVCosWLAAU6ZMgVKpRI0aNRAdHY0mTZpIHY2IiEoQyQ9LvY158+YhMjIS27dvh6WlZb7rhIaGwsHBQf1wdXUt5pT5Y6/R3LNnz7BkyRIolUr07dsXcXFxLDZERPQKScuNo6MjTE1NkZycnGd5cnIynJ2dX7vtggULMG/ePPz2229o1KhRgetNnjwZqamp6sedO3e0kl0TQghkKnKRqVAW+3sbkjJlyuDHH3/EqlWrsGnTJtjZ2UkdiYiISiBJD0vJ5XK4u7vj4MGD6NGjBwCoJwePGjWqwO2++eYbzJkzB/v27YOHh8dr38PCwkLSuRhCCPQKj8WZv59KlkFfqVQqhIaGonLlyujfvz8AoHXr1mjdurXEyYiIqCST/CJ+wcHBCAgIgIeHBzw9PbF48WJkZGQgKCgIADBw4EBUqFABoaGhAICvv/4aM2bMwObNm1GlShUkJSUBAGxtbWFrayvZ5yhIVo7ylWLjUbk0JxO/QXJyMgYMGID9+/fD2toa7dq1Q4UKFaSORUREekDycuPr64tHjx5hxowZSEpKgpubG/bu3aueZHz79m2YmPz/0bMVK1ZAoVCgV69eeV4nJCQEX375ZXFG19jpad6wlpvCytyUk4lf49ChQ/D390dSUhKsrKywbNkylC9fXupYRESkJ2RCGNdl5dLS0uDg4IDU1FTY29vr/P0yFbmoN2MfACBxlg+s5ZL3yRJLqVRi9uzZmDVrFlQqFerXr4/o6GjUq1dP6mhERCQxTb6/+U2rQ/9MJOYk4sLIzc1Fx44d1RdjHDx4ML777jtYW1tLnIyIiPQNy42OcCKxZszMzNCsWTMcP34cK1euRL9+/aSOREREekqvr3NTkv13IjEnEb8qNzcXjx49Uj+fNWsWzp49y2JDRERvhSM3xeD0NG+UtZFzEvG/3L17F3379kV2djZiYmIgl8thbm6O6tWrSx2NiIj0HEduioG1nGdH/dvu3bvh5uaGmJgYXL58GRcuXJA6EhERGRCWGyo2OTk5mDBhAjp37ozHjx+jadOmiIuLQ9OmTaWORkREBoSHpahY/P333/Dz88Px48cBAKNHj8b8+fN5J28iItI6lhsqFp988gmOHz8OBwcHrF27Fj179pQ6EhERGSgelqJisWLFCnh7eyM+Pp7FhoiIdIrlhnTi5s2bWLNmjfp5jRo1sH//flStWlXCVEREZAx4WIq07qeffsLgwYORlpaGKlWqwNvbW+pIRERkRDhyQ1rz4sULjBo1Cr169UJqaireffdd1KxZU+pYRERkZFhuSCuuXbuGFi1aICwsDAAwYcIEHDlyBJUrV5Y4GRERGRselqK3tmXLFgwePBjp6ekoW7Ys1q9fj06dOkkdi4iIjBTLDb2158+fIz09Ha1atcLmzZtRsWJFqSMREZERY7mhIsnNzYWZ2T+/fQIDA2Fra4uPPvpIvYyIiEgqnHNDGtuwYQMaNWqEx48fAwBkMhl69+7NYkNERCUCyw0VWkZGBgYNGoSBAwfi0qVL+O6776SORERE9Ar+U5sK5eLFi+jTpw8SExMhk8kQEhKCadOmSR2LiIjoFSw39FpCCERERGDkyJHIysqCs7MzNm/ejHbt2kkdjYiIKF88LEWvtXz5cgwaNAhZWVn44IMPkJCQwGJDREQlGssNvVa/fv1Qo0YNzJkzB3v37oWTk5PUkYiIiF6Lh6V0RAipExSNEAIHDhyAt7c3ZDIZSpUqhfPnz8PS0lLqaERERIXCkRsdEEKgd3is1DE0lpaWBn9/f3To0AGrV69WL2exISIifcKRGx3IylEi8UEaAKCeiz2szE0lTvRm8fHx6NOnD65duwYzMzNkZWVJHYmIiKhIWG50bMswL8hkMqljFEgIgeXLlyM4OBgKhQKVKlVCZGQkvLy8pI5GRERUJCw3OlaCew2ePXuGTz75BD/99BMAoFu3bli3bh3KlCkjcTIiIqKi45wbLRNCIFOhlDpGoZw/fx7bt2+Hubk5Fi1ahB07drDYEBGR3uPIjRYJIdArPBZn/n4qdZRCadWqFZYtWwYPDw80a9ZM6jhERERawZEbLcrKUeYpNh6VS5eoycRPnjyBv78/rly5ol42fPhwFhsiIjIoHLnRkdPTvFHWRl5iJhPHxsbCz88Pt2/fxrVr13DixIkSk42IiEibOHKjI9Zy0xJRHlQqFebPn4/WrVvj9u3bqF69OsLDw0tENiIiIl3gyI0BS0lJQUBAAHbv3g0A8PX1xapVq2Bvby9xMiIiIt1huTFQ165dQ9u2bXHv3j1YWlpiyZIlGDJkCEdsiIjI4LHcGKjKlSujcuXKsLW1RXR0NBo1aiR1JCIiomLBcmNAHj16BAcHB8jlcpibm2Pr1q2ws7ODra2t1NGIiIiKDScUG4hDhw6hUaNGmDJlinqZi4sLiw0RERkdlhs9p1QqMXPmTHh7eyMpKQl79+5FZmam1LGIiIgkw3KjRUIU7/s9ePAAHTp0wJdffgmVSoVBgwbh5MmTsLa2Lt4gREREJQjn3GiJEAK9w2OL7f3279+P/v374+HDh7CxscGKFSswYMCAYnt/IiKikorlRkuycpRIfJAGAKjnYq/T2y48e/YMvXv3RmpqKho2bIjo6GjUqVNHZ+9HRESkT1hudGDLMC+dXk+mVKlSCA8Px6FDh7B48WJYWVnp7L2IiIj0DcuNDuii1+zZsweWlpZo164dAMDPzw9+fn7afyMiIiI9xwnFJVxOTg4mTpyITp06oW/fvkhOTpY6EhERUYnGkZsS7Pbt2/Dz80Ns7D8TlXv16gUHBweJUxEREZVsLDcl1M6dOxEYGIinT5/CwcEB33//PT7++GOpYxEREZV4PCxVwiiVSgQHB6N79+54+vQpmjVrhri4OBYbIiKiQmK5KWFMTEzw8OFDAMDnn3+OmJgYVKtWTeJURERE+oOHpUqI3NxcmJmZQSaTYcWKFejXrx8+/PBDqWMRERHpHY7cSCw7OxujR4/Gxx9/DPG/+zfY2dmx2BARERURR24kdO3aNfj6+iIuLg4AEBMTg1atWkmcioiISL9x5EYiUVFRaNq0KeLi4lC2bFn8+uuvLDZERERawHJTzLKysjBs2DD4+fkhPT0dLVu2REJCAjp37ix1NCIiIoPAclPM/Pz8sHLlSshkMkyZMgWHDh1CxYoVpY5FRERkMDjnpphNmTIFZ86cwdq1a9GhQwep4xARERkclhsdy8zMxKlTp9CmTRsAQPPmzXH9+nVYWFhInIyIiMgw8bCUDiUmJsLT0xMdO3bEuXPn1MtZbIiIiHSnRJSbsLAwVKlSBZaWlmjevDlOnjz52vW3bNmCOnXqwNLSEg0bNsTu3buLKWnhCCGwbt06eHh44OLFiyhVqhTS0tKkjkVERGQUJC83UVFRCA4ORkhICOLi4tC4cWP4+Piob0HwX3/++Sf69u2LwYMHIz4+Hj169ECPHj1w4cKFYk5esKFDh2LQoEHIysrCBx98gISEBLRs2VLqWEREREZBJl5eFlcizZs3R7NmzbBs2TIAgEqlgqurK0aPHo1Jkya9sr6vry8yMjLw66+/qpe9++67cHNzQ3h4+BvfLy0tDQ4ODkhNTYW9vb3WPkemIhf1ZuwDANxe+DFkyhzMmjULkydPhomJ5B2SiIhIr2ny/S3pt65CocCZM2fg7e2tXmZiYgJvb2/Exsbmu01sbGye9QHAx8enwPWzs7ORlpaW56FrLi4uOHToEKZOncpiQ0REVMwk/eZNSUmBUqmEk5NTnuVOTk5ISkrKd5ukpCSN1g8NDYWDg4P64erqqp3wrxEbG4vWrVvr/H2IiIjoVQZ/KvjkyZMRHBysfp6WlqaTgmNlborEWT7qXxMREZE0JC03jo6OMDU1RXJycp7lycnJcHZ2zncbZ2dnjda3sLAollOvZTIZrOUG3xWJiIhKPEkPS8nlcri7u+PgwYPqZSqVCgcPHoSXl1e+23h5eeVZHwD2799f4PpERERkXCQfaggODkZAQAA8PDzg6emJxYsXIyMjA0FBQQCAgQMHokKFCggNDQUAjBkzBm3atMG3336Lzp07IzIyEqdPn8aqVauk/BhERERUQkhebnx9ffHo0SPMmDEDSUlJcHNzw969e9WThm/fvp3njKMWLVpg8+bNmDZtGqZMmYKaNWtix44daNCggVQfgYiIiEoQya9zU9x0dZ0bIiIi0h29uc4NERERkbax3BAREZFBYbkhIiIig8JyQ0RERAaF5YaIiIgMCssNERERGRSWGyIiIjIoLDdERERkUFhuiIiIyKBIfvuF4vbygsxpaWkSJyEiIqLCevm9XZgbKxhduUlPTwcAuLq6SpyEiIiINJWeng4HB4fXrmN095ZSqVS4f/8+7OzsIJPJtPraaWlpcHV1xZ07d3jfKh3ifi4e3M/Fg/u5+HBfFw9d7WchBNLT01G+fPk8N9TOj9GN3JiYmKBixYo6fQ97e3v+wSkG3M/Fg/u5eHA/Fx/u6+Khi/38phGblzihmIiIiAwKyw0REREZFJYbLbKwsEBISAgsLCykjmLQuJ+LB/dz8eB+Lj7c18WjJOxno5tQTERERIaNIzdERERkUFhuiIiIyKCw3BAREZFBYbkhIiIig8Jyo6GwsDBUqVIFlpaWaN68OU6ePPna9bds2YI6derA0tISDRs2xO7du4spqX7TZD+vXr0arVq1QunSpVG6dGl4e3u/8f8L/UPT388vRUZGQiaToUePHroNaCA03c/Pnj3DyJEj4eLiAgsLC9SqVYt/dxSCpvt58eLFqF27NqysrODq6oqxY8fixYsXxZRWP/3xxx/o2rUrypcvD5lMhh07drxxm8OHD6Np06awsLBAjRo1EBERofOcEFRokZGRQi6Xi7Vr14qLFy+KIUOGiFKlSonk5OR81z927JgwNTUV33zzjUhMTBTTpk0T5ubm4vz588WcXL9oup/9/f1FWFiYiI+PF5cuXRKBgYHCwcFB3L17t5iT6xdN9/NLN2/eFBUqVBCtWrUS3bt3L56wekzT/ZydnS08PDxEp06dRExMjLh586Y4fPiwSEhIKObk+kXT/bxp0yZhYWEhNm3aJG7evCn27dsnXFxcxNixY4s5uX7ZvXu3mDp1qti2bZsAILZv3/7a9W/cuCGsra1FcHCwSExMFEuXLhWmpqZi7969Os3JcqMBT09PMXLkSPVzpVIpypcvL0JDQ/Ndv0+fPqJz5855ljVv3lx8+umnOs2p7zTdz/+Vm5sr7OzsxA8//KCriAahKPs5NzdXtGjRQqxZs0YEBASw3BSCpvt5xYoVolq1akKhUBRXRIOg6X4eOXKkeP/99/MsCw4OFu+9955OcxqSwpSbCRMmiPr16+dZ5uvrK3x8fHSYTAgeliokhUKBM2fOwNvbW73MxMQE3t7eiI2NzXeb2NjYPOsDgI+PT4HrU9H2839lZmYiJycHZcqU0VVMvVfU/Txr1iyUK1cOgwcPLo6Yeq8o+3nnzp3w8vLCyJEj4eTkhAYNGmDu3LlQKpXFFVvvFGU/t2jRAmfOnFEfurpx4wZ2796NTp06FUtmYyHV96DR3TizqFJSUqBUKuHk5JRnuZOTEy5fvpzvNklJSfmun5SUpLOc+q4o+/m/Jk6ciPLly7/yB4r+X1H2c0xMDL7//nskJCQUQ0LDUJT9fOPGDfz+++/o168fdu/ejWvXrmHEiBHIyclBSEhIccTWO0XZz/7+/khJSUHLli0hhEBubi6GDRuGKVOmFEdko1HQ92BaWhqysrJgZWWlk/flyA0ZlHnz5iEyMhLbt2+HpaWl1HEMRnp6OgYMGIDVq1fD0dFR6jgGTaVSoVy5cli1ahXc3d3h6+uLqVOnIjw8XOpoBuXw4cOYO3culi9fjri4OGzbtg27du3CV199JXU00gKO3BSSo6MjTE1NkZycnGd5cnIynJ2d893G2dlZo/WpaPv5pQULFmDevHk4cOAAGjVqpMuYek/T/Xz9+nXcunULXbt2VS9TqVQAADMzM1y5cgXVq1fXbWg9VJTfzy4uLjA3N4epqal6Wd26dZGUlASFQgG5XK7TzPqoKPt5+vTpGDBgAD755BMAQMOGDZGRkYGhQ4di6tSpMDHhv/21oaDvQXt7e52N2gAcuSk0uVwOd3d3HDx4UL1MpVLh4MGD8PLyyncbLy+vPOsDwP79+wtcn4q2nwHgm2++wVdffYW9e/fCw8OjOKLqNU33c506dXD+/HkkJCSoH926dUO7du2QkJAAV1fX4oyvN4ry+/m9997DtWvX1OURAK5evQoXFxcWmwIUZT9nZma+UmBeFkrBWy5qjWTfgzqdrmxgIiMjhYWFhYiIiBCJiYli6NCholSpUiIpKUkIIcSAAQPEpEmT1OsfO3ZMmJmZiQULFohLly6JkJAQngpeCJru53nz5gm5XC62bt0qHjx4oH6kp6dL9RH0gqb7+b94tlThaLqfb9++Lezs7MSoUaPElStXxK+//irKlSsnZs+eLdVH0Aua7ueQkBBhZ2cnfvzxR3Hjxg3x22+/ierVq4s+ffpI9RH0Qnp6uoiPjxfx8fECgFi4cKGIj48Xf//9txBCiEmTJokBAwao1395KvgXX3whLl26JMLCwngqeEm0dOlSUalSJSGXy4Wnp6c4fvy4+mdt2rQRAQEBedaPjo4WtWrVEnK5XNSvX1/s2rWrmBPrJ032c+XKlQWAVx4hISHFH1zPaPr7+d9YbgpP0/38559/iubNmwsLCwtRrVo1MWfOHJGbm1vMqfWPJvs5JydHfPnll6J69erC0tJSuLq6ihEjRoinT58Wf3A9cujQoXz/vn25bwMCAkSbNm1e2cbNzU3I5XJRrVo1sW7dOp3nlAnB8TciIiIyHJxzQ0RERAaF5YaIiIgMCssNERERGRSWGyIiIjIoLDdERERkUFhuiIiIyKCw3BAREZFBYbkhojwiIiJQqlQpqWMUmUwmw44dO167TmBgIHr06FEseYio+LHcEBmgwMBAyGSyVx7Xrl2TOhoiIiLUeUxMTFCxYkUEBQXh4cOHWnn9Bw8e4MMPPwQA3Lp1CzKZDAkJCXnWWbJkCSIiIrTyfgX58ssv1Z/T1NQUrq6uGDp0KJ48eaLR67CIEWmOdwUnMlAdO3bEunXr8ix75513JEqTl729Pa5cuQKVSoWzZ88iKCgI9+/fx759+976td9093gAcHBweOv3KYz69evjwIEDUCqVuHTpEgYNGoTU1FRERUUVy/sTGSuO3BAZKAsLCzg7O+d5mJqaYuHChWjYsCFsbGzg6uqKESNG4Pnz5wW+ztmzZ9GuXTvY2dnB3t4e7u7uOH36tPrnMTExaNWqFaysrODq6orPPvsMGRkZr80mk8ng7OyM8uXL48MPP8Rnn32GAwcOICsrCyqVCrNmzULFihVhYWEBNzc37N27V72tQqHAqFGj4OLiAktLS1SuXBmhoaF5XvvlYamqVasCAJo0aQKZTIa2bdsCyDsasmrVKpQvXz7PXbgBoHv37hg0aJD6+c8//4ymTZvC0tIS1apVw8yZM5Gbm/vaz2lmZgZnZ2dUqFAB3t7e6N27N/bv36/+uVKpxODBg1G1alVYWVmhdu3aWLJkifrnX375JX744Qf8/PPP6lGgw4cPAwDu3LmDPn36oFSpUihTpgy6d++OW7duvTYPkbFguSEyMiYmJvjuu+9w8eJF/PDDD/j9998xYcKEAtfv168fKlasiFOnTuHMmTOYNGkSzM3NAQDXr19Hx44d8fHHH+PcuXOIiopCTEwMRo0apVEmKysrqFQq5ObmYsmSJfj222+xYMECnDt3Dj4+PujWrRv++usvAMB3332HnTt3Ijo6GleuXMGmTZtQpUqVfF/35MmTAIADBw7gwYMH2LZt2yvr9O7dG48fP8ahQ4fUy548eYK9e/eiX79+AICjR49i4MCBGDNmDBITE7Fy5UpERERgzpw5hf6Mt27dwr59+yCXy9XLVCoVKlasiC1btiAxMREzZszAlClTEB0dDQAYP348+vTpg44dO+LBgwd48OABWrRogZycHPj4+MDOzg5Hjx7FsWPHYGtri44dO0KhUBQ6E5HB0vmtOYmo2AUEBAhTU1NhY2OjfvTq1Svfdbds2SLKli2rfr5u3Trh4OCgfm5nZyciIiLy3Xbw4MFi6NCheZYdPXpUmJiYiKysrHy3+e/rX716VdSqVUt4eHgIIYQoX768mDNnTp5tmjVrJkaMGCGEEGL06NHi/fffFyqVKt/XByC2b98uhBDi5s2bAoCIj4/Ps85/72jevXt3MWjQIPXzlStXivLlywulUimEEKJ9+/Zi7ty5eV5jw4YNwsXFJd8MQggREhIiTExMhI2NjbC0tFTfPXnhwoUFbiOEECNHjhQff/xxgVlfvnft2rXz7IPs7GxhZWUl9u3b99rXJzIGnHNDZKDatWuHFStWqJ/b2NgA+GcUIzQ0FJcvX0ZaWhpyc3Px4sULZGZmwtra+pXXCQ4OxieffIINGzaoD61Ur14dwD+HrM6dO4dNmzap1xdCQKVS4ebNm6hbt26+2VJTU2FrawuVSoUXL16gZcuWWLNmDdLS0nD//n289957edZ/7733cPbsWQD/HFL64IMPULt2bXTs2BFdunRBhw4d3mpf9evXD0OGDMHy5cthYWGBTZs2wc/PDyYmJurPeezYsTwjNUql8rX7DQBq166NnTt34sWLF9i4cSMSEhIwevToPOuEhYVh7dq1uH37NrKysqBQKODm5vbavGfPnsW1a9dgZ2eXZ/mLFy9w/fr1IuwBIsPCckNkoGxsbFCjRo08y27duoUuXbpg+PDhmDNnDsqUKYOYmBgMHjwYCoUi3y/pL7/8Ev7+/ti1axf27NmDkJAQREZG4qOPPsLz58/x6aef4rPPPntlu0qVKhWYzc7ODnFxcTAxMYGLiwusrKwAAGlpaW/8XE2bNsXNmzexZ88eHDhwAH369IG3tze2bt36xm0L0rVrVwghsGvXLjRr1gxHjx7FokWL1D9//vw5Zs6ciZ49e76yraWlZYGvK5fL1f8P5s2bh86dO2PmzJn46quvAACRkZEYP348vv32W3h5ecHOzg7z58/HiRMnXpv3+fPncHd3z1MqXyopk8aJpMRyQ2REzpw5A5VKhW+//VY9KvFyfsfr1KpVC7Vq1cLYsWPRt29frFu3Dh999BGaNm2KxMTEV0rUm5iYmOS7jb29PcqXL49jx46hTZs26uXHjh2Dp6dnnvV8fX3h6+uLXr16oWPHjnjy5AnKlCmT5/Vezm9RKpWvzWNpaYmePXti06ZNuHbtGmrXro2mTZuqf960aVNcuXJF48/5X9OmTcP777+P4cOHqz9nixYtMGLECPU6/x15kcvlr+Rv2rQpoqKiUK5cOdjb279VJiJDxAnFREakRo0ayMnJwdKlS3Hjxg1s2LAB4eHhBa6flZWFUaNG4fDhw/j7779x7NgxnDp1Sn24aeLEifjzzz8xatQoJCQk4K+//sLPP/+s8YTif/viiy/w9ddfIyoqCleuXMGkSZOQkJCAMWPGAAAWLlyIH3/8EZcvX8bVq1exZcsWODs753vhwXLlysHKygp79+5FcnIyUlNTC3zffv36YdeuXVi7dq16IvFLM2bMwPr16zFz5kxcvHgRly5dQmRkJKZNm6bRZ/Py8kKjRo0wd+5cAEDNmjVx+vRp7Nu3D1evXsX06dNx6tSpPNtUqVIF586dw5UrV5CSkoKcnBz069cPjo6O6N69O44ePYqbN2/i8OHD+Oyzz3D37l2NMhEZJKkn/RCR9uU3CfWlhQsXChcXF2FlZSV8fHzE+vXrBQDx9OlTIUTeCb/Z2dnCz89PuLq6CrlcLsqXLy9GjRqVZ7LwyZMnxQcffCBsbW2FjY2NaNSo0SsTgv/tvxOK/0upVIovv/xSVKhQQZibm4vGjRuLPXv2qH++atUq4ebmJmxsbIS9vb1o3769iIuLU/8c/5pQLIQQq1evFq6ursLExES0adOmwP2jVCqFi4uLACCuX7/+Sq69e/eKFi1aCCsrK2Fvby88PT3FqlWrCvwcISEhonHjxq8s//HHH4WFhYW4ffu2ePHihQgMDBQODg6iVKlSYvjw4WLSpEl5tnv48KF6/wIQhw4dEkII8eDBAzFw4EDh6OgoLCwsRLVq1cSQIUNEampqgZmIjIVMCCGkrVdERERE2sPDUkRERGRQWG6IiIjIoLDcEBERkUFhuSEiIiKDwnJDREREBoXlhoiIiAwKyw0REREZFJYbIiIiMigsN0RERGRQWG6IiIjIoLDcEBERkUFhuSEiIiKD8n8YiQBp6C7hwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8632196552988631\n"
     ]
    }
   ],
   "source": [
    "# Create ROC Curve\n",
    "y_pred_proba = logistic.predict_proba(X_train)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_pred_proba)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print ROC Curve Statistics\n",
    "print('ROC AUC Score:', roc_auc_score(y_train, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Truth Table\n",
      "Accuracy Score: 0.9066666666666666\n",
      "Confusion Matrix: [[67  1]\n",
      " [ 6  1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9537815126050421\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = logistic.predict(X_test)\n",
    "\n",
    "# Calculate truth table for test\n",
    "print('Test Truth Table')\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred_test))\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Create ROC Curve for test\n",
    "y_pred_proba = logistic.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print ROC Curve Statistics\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907258064516129\n",
      "Confusion Matrix:\n",
      "[[667   7]\n",
      " [ 62   8]]\n",
      "ROC AUC Score: 0.8739296311996609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate through each training and testing set from LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    logistic = linear_model.LogisticRegression(class_weight=class_weights)\n",
    "    logistic.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = logistic.predict(X_test)\n",
    "\n",
    "    # Store the predictions and true labels\n",
    "    predictions.append(y_pred)\n",
    "    true_labels.append(y_test.values[0])\n",
    "\n",
    "# Convert lists to arrays for easier manipulation\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "y_pred_proba = logistic.predict_proba(X)[:,1]\n",
    "roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8978494623655914\n",
      "Confusion Matrix:\n",
      "[[667   7]\n",
      " [ 69   1]]\n",
      "ROC AUC Score: 0.8763459092835947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds\n",
    "k = 10\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Iterate through each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    logistic = linear_model.LogisticRegression(class_weight=class_weights)\n",
    "    logistic.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = logistic.predict(X_test)\n",
    "\n",
    "    # Store the predictions and true labels\n",
    "    predictions.extend(y_pred)\n",
    "    true_labels.extend(y_test)\n",
    "\n",
    "# Convert lists to arrays for easier manipulation\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "y_pred_proba = logistic.predict_proba(X)[:,1]\n",
    "roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Subset Regression using BIC:\n",
      "BIC: 365.72154205076663\n",
      "Variables: ('RE/TA', 'ME/TL')\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Default   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      741\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 18 May 2024   Pseudo R-squ.:                  0.2547\n",
      "Time:                        13:58:37   Log-Likelihood:                -172.94\n",
      "converged:                       True   LL-Null:                       -232.05\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.145e-26\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.8320      0.235     -3.543      0.000      -1.292      -0.372\n",
      "RE/TA         -1.1031      0.288     -3.825      0.000      -1.668      -0.538\n",
      "ME/TL         -1.7026      0.315     -5.408      0.000      -2.320      -1.086\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Function to perform Best Subset Regression\n",
    "def best_subset_regression(X, y, criterion='aic'):\n",
    "    results = []\n",
    "    for k in range(1, len(X.columns) + 1):\n",
    "        subsets = itertools.combinations(X.columns, k)\n",
    "        for subset in subsets:\n",
    "            model = sm.Logit(y, sm.add_constant(X[list(subset)])).fit(disp=0)\n",
    "            if criterion == 'aic':\n",
    "                results.append((model, model.aic, subset))\n",
    "            elif criterion == 'bic':\n",
    "                results.append((model, model.bic, subset))\n",
    "    \n",
    "    # Select the model with the minimum AIC/BIC\n",
    "    best_model = min(results, key=lambda x: x[1])\n",
    "    return best_model\n",
    "\n",
    "# Perform Best Subset Regression using BIC\n",
    "best_model_bic = best_subset_regression(X, y, criterion='bic')\n",
    "print(\"\\nBest Subset Regression using BIC:\")\n",
    "print(\"BIC:\", best_model_bic[1])\n",
    "print(\"Variables:\", best_model_bic[2])\n",
    "print(best_model_bic[0].summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge coefficients: [ 0.01264678 -0.19656106 -1.03983187 -0.00933357  0.16121051]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df = credit_data\n",
    "\n",
    "X = credit_data[['WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA']]  # predictors\n",
    "y = credit_data['Default']   # response\n",
    "\n",
    "ridge = Ridge()\n",
    "parameters = {'alpha': np.logspace(-4, 4, 100)}\n",
    "ridge_cv = GridSearchCV(ridge, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X, y)\n",
    "\n",
    "ridge_best_model = ridge_cv.best_estimator_\n",
    "ridge_coefficients = ridge_best_model.coef_\n",
    "print(\"Ridge coefficients:\", ridge_coefficients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO coefficients: [ 0.00666395 -0.19746534 -0.95038793 -0.00953055  0.15669492]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "parameters = {'alpha': np.logspace(-4, 4, 100)}\n",
    "lasso_cv = GridSearchCV(lasso, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X, y)\n",
    "\n",
    "lasso_best_model = lasso_cv.best_estimator_\n",
    "lasso_coefficients = lasso_best_model.coef_\n",
    "print(\"LASSO coefficients:\", lasso_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.866e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.868e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.815e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.749e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.826e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.896e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.840e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.851e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.852e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.784e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.862e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.782e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.848e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.816e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.863e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.860e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.874e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.834e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.893e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.848e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.893e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.854e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.863e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.829e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.901e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.866e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.912e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.872e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.854e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.928e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.861e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.861e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.899e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.868e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.019e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.021e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.868e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.944e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.907e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.029e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.913e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.962e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.888e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.893e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.047e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.893e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.899e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.059e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.060e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.907e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.063e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.947e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.947e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.991e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.068e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.992e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.991e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.917e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.075e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.076e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.078e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.079e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.080e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.962e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.924e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.005e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.924e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.084e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.007e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.087e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.008e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.007e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.928e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.087e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+01, tolerance: 6.029e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.868e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+01, tolerance: 6.188e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+01, tolerance: 5.869e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.030e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 5.950e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 2.774e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net coefficients: [ 0.00949651 -0.19815175 -0.95745231 -0.00955268  0.15875159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+01, tolerance: 6.341e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elastic_net = ElasticNet()\n",
    "parameters = {'alpha': np.logspace(-4, 4, 100), 'l1_ratio': np.linspace(0, 1, 10)}\n",
    "elastic_net_cv = GridSearchCV(elastic_net, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "elastic_net_cv.fit(X, y)\n",
    "\n",
    "elastic_net_best_model = elastic_net_cv.best_estimator_\n",
    "elastic_net_coefficients = elastic_net_best_model.coef_\n",
    "print(\"Elastic Net coefficients:\", elastic_net_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on Coefficients\n",
    "\n",
    "Let's analyze and comment on the coefficients obtained from Ridge, LASSO, and Elastic Net regression models. Here's a detailed commentary:\n",
    "\n",
    "#### Ridge Regression Coefficients\n",
    "\n",
    "Ridge coefficients: [ 0.01264678 -0.19656106 -1.03983187 -0.00933357  0.16121051]\n",
    "\n",
    "- **Overview**: Ridge regression shrinks the coefficients but retains all features in the model. It uses \\( \\ell_2 \\)-norm regularization, which penalizes the sum of the squared coefficients.\n",
    "- **Interpretation**:\n",
    "  - The first coefficient (0.0126) indicates a small positive effect of the corresponding predictor.\n",
    "  - The second coefficient (-0.1966) indicates a moderate negative effect.\n",
    "  - The third coefficient (-1.0398) indicates a strong negative effect, suggesting this predictor is significantly inversely related to the response variable.\n",
    "  - The fourth coefficient (-0.0093) indicates a very small negative effect.\n",
    "  - The fifth coefficient (0.1612) indicates a moderate positive effect.\n",
    "- **Key Point**: Ridge does not set any coefficients to zero, hence all features are retained in the model.\n",
    "\n",
    "#### LASSO Regression Coefficients\n",
    "\n",
    "LASSO coefficients: [ 0.00666395 -0.19746534 -0.95038793 -0.00953055  0.15669492]\n",
    "\n",
    "- **Overview**: LASSO regression can shrink some coefficients to exactly zero using \\( \\ell_1 \\)-norm regularization, which is useful for feature selection.\n",
    "- **Interpretation**:\n",
    "  - The first coefficient (0.0067) is close to zero but positive, indicating a minimal positive effect.\n",
    "  - The second coefficient (-0.1975) is slightly stronger than in Ridge, indicating a moderate negative effect.\n",
    "  - The third coefficient (-0.9504) is still negative but slightly less strong than in Ridge.\n",
    "  - The fourth coefficient (-0.0095) indicates a very small negative effect, similar to Ridge.\n",
    "  - The fifth coefficient (0.1567) indicates a moderate positive effect.\n",
    "- **Key Point**: In this case, none of the coefficients are exactly zero, indicating that LASSO did not perform feature selection here, but the coefficients are generally smaller in magnitude compared to Ridge.\n",
    "\n",
    "#### Elastic Net Regression Coefficients\n",
    "\n",
    "Elastic Net coefficients: [ 0.00949651 -0.19815175 -0.95745231 -0.00955268  0.15875159]\n",
    "\n",
    "- **Overview**: Elastic Net combines both \\( \\ell_1 \\) and \\( \\ell_2 \\)-norm regularization, balancing Ridge and LASSO properties.\n",
    "- **Interpretation**:\n",
    "  - The first coefficient (0.0095) is positive and small, indicating a minimal positive effect.\n",
    "  - The second coefficient (-0.1982) is a moderate negative effect, similar to LASSO.\n",
    "  - The third coefficient (-0.9575) is negative, closer to LASSO but slightly more than Ridge.\n",
    "  - The fourth coefficient (-0.0096) indicates a very small negative effect, very close to Ridge and LASSO.\n",
    "  - The fifth coefficient (0.1588) indicates a moderate positive effect, similar to LASSO and Ridge.\n",
    "- **Key Point**: Elastic Net coefficients are similar to those of LASSO but slightly more balanced, showcasing a compromise between the Ridge and LASSO results.\n",
    "\n",
    "### Summary of Comparison\n",
    "- **Magnitude**: Ridge generally produces larger coefficients compared to LASSO and Elastic Net due to its \\( \\ell_2 \\) penalty.\n",
    "- **Sparsity**: While LASSO is known for sparsity, in this case, it didn't set any coefficients to zero. Elastic Net did not set any coefficients to zero either but provides a balance between Ridge and LASSO.\n",
    "- **Feature Retention**: All models retained all features in this scenario, but if there were more noise or redundant features, LASSO or Elastic Net might set some coefficients to zero.\n",
    "\n",
    "These coefficients indicate how each model treats the predictors in relation to the response variable, showing slight variations based on the type of regularization applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "df = credit_data\n",
    "\n",
    "X = credit_data[['WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA']]  # predictors\n",
    "y = credit_data['Default']   # response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "alphas = np.logspace(-6, 6, 13)\n",
    "\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "param_grid_ridge = {'alpha': alphas}\n",
    "param_grid_lasso = {'alpha': alphas}\n",
    "param_grid_elastic_net = {'alpha': alphas, 'l1_ratio': [0.2, 0.5, 0.8]}\n",
    "\n",
    "ridge_cv = GridSearchCV(ridge, param_grid_ridge, cv=10, scoring='neg_mean_squared_error')\n",
    "lasso_cv = GridSearchCV(lasso, param_grid_lasso, cv=10, scoring='neg_mean_squared_error')\n",
    "elastic_net_cv = GridSearchCV(elastic_net, param_grid_elastic_net, cv=10, scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "ridge_cv.fit(X, y)\n",
    "lasso_cv.fit(X, y)\n",
    "elastic_net_cv.fit(X, y)\n",
    "\n",
    "best_ridge = ridge_cv.best_estimator_\n",
    "best_lasso = lasso_cv.best_estimator_\n",
    "best_elastic_net = elastic_net_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores = cross_val_score(best_ridge, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "lasso_scores = cross_val_score(best_lasso, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "elastic_net_scores = cross_val_score(best_elastic_net, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "ridge_rmse = np.sqrt(-ridge_scores)\n",
    "lasso_rmse = np.sqrt(-lasso_scores)\n",
    "elastic_net_rmse = np.sqrt(-elastic_net_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: Mean = 0.2751, Std = 0.0316\n",
      "LASSO RMSE: Mean = 0.2751, Std = 0.0316\n",
      "Elastic Net RMSE: Mean = 0.2751, Std = 0.0316\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ridge RMSE: Mean = {ridge_rmse.mean():.4f}, Std = {ridge_rmse.std():.4f}\")\n",
    "print(f\"LASSO RMSE: Mean = {lasso_rmse.mean():.4f}, Std = {lasso_rmse.std():.4f}\")\n",
    "print(f\"Elastic Net RMSE: Mean = {elastic_net_rmse.mean():.4f}, Std = {elastic_net_rmse.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load the data\n",
    "yield_data = pd.read_csv('csv_files/turkish_yields.csv')\n",
    "\n",
    "# Changing only the first column name to date\n",
    "yield_data.columns.values[0] = \"Date\"\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "yield_data[\"Date\"] = pd.to_datetime(yield_data[\"Date\"], format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio for each Principal Component:\n",
      "PC1: 0.9474\n",
      "PC2: 0.0433\n",
      "PC3: 0.0082\n",
      "PC4: 0.0010\n",
      "PC5: 0.0000\n",
      "PC6: 0.0000\n",
      "PC7: 0.0000\n",
      "PC8: 0.0000\n",
      "PC9: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "# Drop non-numeric columns if any\n",
    "data_numeric = yield_data.drop('Date', axis=1)  # Assuming 'Date' is the non-numeric column\n",
    "\n",
    "# Handle missing values if any\n",
    "data_numeric.dropna(inplace=True)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_numeric)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(data_scaled)\n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio for each principal component\n",
    "print(\"Explained Variance Ratio for each Principal Component:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC{i+1}: {ratio:.4f}\")\n",
    "\n",
    "# You can also access the principal components themselves\n",
    "principal_components = pca.components_\n",
    "\n",
    "# Transform the original data to the new PCA space\n",
    "data_pca = pca.transform(data_scaled)\n",
    "\n",
    "# Convert the transformed data to a DataFrame for further analysis if needed\n",
    "data_pca_df = pd.DataFrame(data_pca, columns=[f'PC{i+1}' for i in range(data_pca.shape[1])])\n",
    "\n",
    "# Concatenate the transformed data with the original data (if needed)\n",
    "# final_data = pd.concat([data['Date'], data_pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/f7tm916900ld7h415zrtvygh0000gn/T/ipykernel_92989/3745170632.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mkurt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkurtosis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Variable'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Median'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Skewness'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Kurtosis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkurt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Calculate differences\n",
    "for i in range(1, len(yield_data.columns)):\n",
    "    yield_data[yield_data.columns[i] + '_diff'] = yield_data[yield_data.columns[i]] - yield_data[yield_data.columns[i]].shift(1)\n",
    "\n",
    "# Drop the first row since it will have NaN values due to differencing\n",
    "yield_data.dropna(inplace=True)\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "statistics = pd.DataFrame(columns=['Variable', 'Mean', 'Median', 'Skewness', 'Kurtosis'])\n",
    "\n",
    "for column in yield_data.columns[1:]:\n",
    "    variable = column.split('_')[0]\n",
    "    mean = np.mean(yield_data[column])\n",
    "    median = np.median(yield_data[column])\n",
    "    sk = skew(yield_data[column])\n",
    "    kurt = kurtosis(yield_data[column])\n",
    "    statistics = statistics.append({'Variable': variable, 'Mean': mean, 'Median': median, 'Skewness': sk, 'Kurtosis': kurt}, ignore_index=True)\n",
    "\n",
    "display(statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C - a: ChatGPT Comments\n",
    "- The interest rate levels show a consistent right-skewed distribution across different time intervals, with heavier tails indicating the presence of outliers or extreme values.\n",
    "- Interest rate differences display even heavier tails with significantly higher kurtosis values, suggesting extreme fluctuations or outliers in the data.\n",
    "- The skewness values for interest rate differences vary, indicating varying degrees of right-skewness in the changes over time.\n",
    "- Extremely high kurtosis values for interest rate differences suggest that the distribution of changes in interest rates deviates significantly from a normal distribution, indicating high volatility or non-stationarity in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C - b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a time series plot of the yield spread\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(yield_data[\"Date\"], yield_data['yield_spread'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Yield Spread')\n",
    "plt.title('Yield Spread Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of months with positive 10-year yield: 2658\n",
      "Number of months with positive 2-year yield: 2658\n"
     ]
    }
   ],
   "source": [
    "# Count the number of months where yields are positive\n",
    "positive_10Y = (yield_data['X3600'] > 0).sum()\n",
    "positive_2Y = (yield_data['X720'] > 0).sum()\n",
    "\n",
    "print(\"Number of months with positive 10-year yield:\", positive_10Y)\n",
    "print(\"Number of months with positive 2-year yield:\", positive_2Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periods of Yield Curve Flattening:\n",
      "10.05.2011\n",
      "13.05.2011\n",
      "17.05.2011\n",
      "18.05.2011\n",
      "20.05.2011\n",
      "23.05.2011\n",
      "24.05.2011\n",
      "01.06.2011\n",
      "02.06.2011\n",
      "03.06.2011\n",
      "06.06.2011\n",
      "09.06.2011\n",
      "10.06.2011\n",
      "13.06.2011\n",
      "15.06.2011\n",
      "20.06.2011\n",
      "21.06.2011\n",
      "22.06.2011\n",
      "23.06.2011\n",
      "27.06.2011\n",
      "28.06.2011\n",
      "04.07.2011\n",
      "08.07.2011\n",
      "12.07.2011\n",
      "13.07.2011\n",
      "18.07.2011\n",
      "25.07.2011\n",
      "27.07.2011\n",
      "29.07.2011\n",
      "01.08.2011\n",
      "02.08.2011\n",
      "03.08.2011\n",
      "04.08.2011\n",
      "08.08.2011\n",
      "12.08.2011\n",
      "16.08.2011\n",
      "18.08.2011\n",
      "19.08.2011\n",
      "22.08.2011\n",
      "23.08.2011\n",
      "24.08.2011\n",
      "29.08.2011\n",
      "05.09.2011\n",
      "08.09.2011\n",
      "14.09.2011\n",
      "15.09.2011\n",
      "19.09.2011\n",
      "20.09.2011\n",
      "23.09.2011\n",
      "27.09.2011\n",
      "29.09.2011\n",
      "03.10.2011\n",
      "05.10.2011\n",
      "06.10.2011\n",
      "07.10.2011\n",
      "10.10.2011\n",
      "14.10.2011\n",
      "18.10.2011\n",
      "19.10.2011\n",
      "20.10.2011\n",
      "21.10.2011\n",
      "24.10.2011\n",
      "26.10.2011\n",
      "31.10.2011\n",
      "02.11.2011\n",
      "03.11.2011\n",
      "04.11.2011\n",
      "11.11.2011\n",
      "15.11.2011\n",
      "17.11.2011\n",
      "21.11.2011\n",
      "22.11.2011\n",
      "23.11.2011\n",
      "25.11.2011\n",
      "28.11.2011\n",
      "29.11.2011\n",
      "30.11.2011\n",
      "08.12.2011\n",
      "09.12.2011\n",
      "12.12.2011\n",
      "13.12.2011\n",
      "15.12.2011\n",
      "19.12.2011\n",
      "20.12.2011\n",
      "21.12.2011\n",
      "22.12.2011\n",
      "26.12.2011\n",
      "28.12.2011\n",
      "29.12.2011\n",
      "30.12.2011\n",
      "03.01.2012\n",
      "04.01.2012\n",
      "05.01.2012\n",
      "06.01.2012\n",
      "10.01.2012\n",
      "16.01.2012\n",
      "17.01.2012\n",
      "20.01.2012\n",
      "23.01.2012\n",
      "02.02.2012\n",
      "06.02.2012\n",
      "07.02.2012\n",
      "08.02.2012\n",
      "09.02.2012\n",
      "14.02.2012\n",
      "15.02.2012\n",
      "16.02.2012\n",
      "23.02.2012\n",
      "24.02.2012\n",
      "27.02.2012\n",
      "29.02.2012\n",
      "02.03.2012\n",
      "06.03.2012\n",
      "07.03.2012\n",
      "12.03.2012\n",
      "14.03.2012\n",
      "19.03.2012\n",
      "20.03.2012\n",
      "22.03.2012\n",
      "23.03.2012\n",
      "03.04.2012\n",
      "09.04.2012\n",
      "10.04.2012\n",
      "11.04.2012\n",
      "12.04.2012\n",
      "13.04.2012\n",
      "16.04.2012\n",
      "17.04.2012\n",
      "18.04.2012\n",
      "19.04.2012\n",
      "25.04.2012\n",
      "26.04.2012\n",
      "27.04.2012\n",
      "30.04.2012\n",
      "02.05.2012\n",
      "03.05.2012\n",
      "04.05.2012\n",
      "07.05.2012\n",
      "09.05.2012\n",
      "10.05.2012\n",
      "11.05.2012\n",
      "15.05.2012\n",
      "22.05.2012\n",
      "24.05.2012\n",
      "25.05.2012\n",
      "28.05.2012\n",
      "29.05.2012\n",
      "05.06.2012\n",
      "08.06.2012\n",
      "11.06.2012\n",
      "15.06.2012\n",
      "18.06.2012\n",
      "19.06.2012\n",
      "29.06.2012\n",
      "09.07.2012\n",
      "11.07.2012\n",
      "12.07.2012\n",
      "13.07.2012\n",
      "17.07.2012\n",
      "18.07.2012\n",
      "19.07.2012\n",
      "24.07.2012\n",
      "25.07.2012\n",
      "07.08.2012\n",
      "08.08.2012\n",
      "09.08.2012\n",
      "14.08.2012\n",
      "17.08.2012\n",
      "23.08.2012\n",
      "24.08.2012\n",
      "03.09.2012\n",
      "12.09.2012\n",
      "17.09.2012\n",
      "18.09.2012\n",
      "20.09.2012\n",
      "24.09.2012\n",
      "25.09.2012\n",
      "26.09.2012\n",
      "27.09.2012\n",
      "04.10.2012\n",
      "08.10.2012\n",
      "10.10.2012\n",
      "18.10.2012\n",
      "31.10.2012\n",
      "01.11.2012\n",
      "05.11.2012\n",
      "06.11.2012\n",
      "14.11.2012\n",
      "16.11.2012\n",
      "19.11.2012\n",
      "20.11.2012\n",
      "22.11.2012\n",
      "23.11.2012\n",
      "26.11.2012\n",
      "29.11.2012\n",
      "30.11.2012\n",
      "03.12.2012\n",
      "04.12.2012\n",
      "11.12.2012\n",
      "12.12.2012\n",
      "13.12.2012\n",
      "14.12.2012\n",
      "17.12.2012\n",
      "18.12.2012\n",
      "19.12.2012\n",
      "20.12.2012\n",
      "24.12.2012\n",
      "25.12.2012\n",
      "26.12.2012\n",
      "31.12.2012\n",
      "03.01.2013\n",
      "08.01.2013\n",
      "11.01.2013\n",
      "15.01.2013\n",
      "16.01.2013\n",
      "17.01.2013\n",
      "25.01.2013\n",
      "31.01.2013\n",
      "08.02.2013\n",
      "12.02.2013\n",
      "13.02.2013\n",
      "14.02.2013\n",
      "15.02.2013\n",
      "18.02.2013\n",
      "22.02.2013\n",
      "25.02.2013\n",
      "26.02.2013\n",
      "27.02.2013\n",
      "28.02.2013\n",
      "01.03.2013\n",
      "04.03.2013\n",
      "12.03.2013\n",
      "14.03.2013\n",
      "15.03.2013\n",
      "18.03.2013\n",
      "19.03.2013\n",
      "20.03.2013\n",
      "22.03.2013\n",
      "25.03.2013\n",
      "26.03.2013\n",
      "27.03.2013\n",
      "01.04.2013\n",
      "04.04.2013\n",
      "05.04.2013\n",
      "09.04.2013\n",
      "11.04.2013\n",
      "12.04.2013\n",
      "15.04.2013\n",
      "19.04.2013\n",
      "22.04.2013\n",
      "24.04.2013\n",
      "30.04.2013\n",
      "02.05.2013\n",
      "07.05.2013\n",
      "08.05.2013\n",
      "10.05.2013\n",
      "17.05.2013\n",
      "20.05.2013\n",
      "21.05.2013\n",
      "23.05.2013\n",
      "24.05.2013\n",
      "29.05.2013\n",
      "30.05.2013\n",
      "31.05.2013\n",
      "03.06.2013\n",
      "05.06.2013\n",
      "06.06.2013\n",
      "12.06.2013\n",
      "13.06.2013\n",
      "18.06.2013\n",
      "20.06.2013\n",
      "21.06.2013\n",
      "25.06.2013\n",
      "26.06.2013\n",
      "27.06.2013\n",
      "01.07.2013\n",
      "03.07.2013\n",
      "05.07.2013\n",
      "09.07.2013\n",
      "10.07.2013\n",
      "12.07.2013\n",
      "15.07.2013\n",
      "17.07.2013\n",
      "18.07.2013\n",
      "22.07.2013\n",
      "23.07.2013\n",
      "26.07.2013\n",
      "01.08.2013\n",
      "05.08.2013\n",
      "06.08.2013\n",
      "12.08.2013\n",
      "13.08.2013\n",
      "14.08.2013\n",
      "15.08.2013\n",
      "16.08.2013\n",
      "19.08.2013\n",
      "26.08.2013\n",
      "03.09.2013\n",
      "05.09.2013\n",
      "19.09.2013\n",
      "23.09.2013\n",
      "25.09.2013\n",
      "26.09.2013\n",
      "27.09.2013\n",
      "30.09.2013\n",
      "01.10.2013\n",
      "03.10.2013\n",
      "04.10.2013\n",
      "09.10.2013\n",
      "11.10.2013\n",
      "14.10.2013\n",
      "30.10.2013\n",
      "01.11.2013\n",
      "04.11.2013\n",
      "05.11.2013\n",
      "07.11.2013\n",
      "08.11.2013\n",
      "11.11.2013\n",
      "13.11.2013\n",
      "14.11.2013\n",
      "15.11.2013\n",
      "18.11.2013\n",
      "19.11.2013\n",
      "20.11.2013\n",
      "22.11.2013\n",
      "29.11.2013\n",
      "02.12.2013\n",
      "05.12.2013\n",
      "06.12.2013\n",
      "09.12.2013\n",
      "13.12.2013\n",
      "18.12.2013\n",
      "20.12.2013\n",
      "23.12.2013\n",
      "25.12.2013\n",
      "27.12.2013\n",
      "30.12.2013\n",
      "03.01.2014\n",
      "06.01.2014\n",
      "08.01.2014\n",
      "10.01.2014\n",
      "13.01.2014\n",
      "17.01.2014\n",
      "20.01.2014\n",
      "21.01.2014\n",
      "22.01.2014\n",
      "24.01.2014\n",
      "27.01.2014\n",
      "28.01.2014\n",
      "29.01.2014\n",
      "30.01.2014\n",
      "31.01.2014\n",
      "03.02.2014\n",
      "06.02.2014\n",
      "07.02.2014\n",
      "10.02.2014\n",
      "17.02.2014\n",
      "21.02.2014\n",
      "24.02.2014\n",
      "27.02.2014\n",
      "06.03.2014\n",
      "11.03.2014\n",
      "14.03.2014\n",
      "17.03.2014\n",
      "24.03.2014\n",
      "25.03.2014\n",
      "26.03.2014\n",
      "28.03.2014\n",
      "31.03.2014\n",
      "02.04.2014\n",
      "03.04.2014\n",
      "04.04.2014\n",
      "10.04.2014\n",
      "11.04.2014\n",
      "16.04.2014\n",
      "17.04.2014\n",
      "18.04.2014\n",
      "24.04.2014\n",
      "29.04.2014\n",
      "02.05.2014\n",
      "05.05.2014\n",
      "09.05.2014\n",
      "13.05.2014\n",
      "15.05.2014\n",
      "16.05.2014\n",
      "20.05.2014\n",
      "21.05.2014\n",
      "29.05.2014\n",
      "02.06.2014\n",
      "05.06.2014\n",
      "06.06.2014\n",
      "13.06.2014\n",
      "16.06.2014\n",
      "17.06.2014\n",
      "18.06.2014\n",
      "19.06.2014\n",
      "23.06.2014\n",
      "01.07.2014\n",
      "03.07.2014\n",
      "07.07.2014\n",
      "14.07.2014\n",
      "17.07.2014\n",
      "21.07.2014\n",
      "22.07.2014\n",
      "24.07.2014\n",
      "31.07.2014\n",
      "01.08.2014\n",
      "04.08.2014\n",
      "05.08.2014\n",
      "06.08.2014\n",
      "08.08.2014\n",
      "12.08.2014\n",
      "13.08.2014\n",
      "19.08.2014\n",
      "25.08.2014\n",
      "27.08.2014\n",
      "29.08.2014\n",
      "01.09.2014\n",
      "03.09.2014\n",
      "04.09.2014\n",
      "08.09.2014\n",
      "10.09.2014\n",
      "12.09.2014\n",
      "17.09.2014\n",
      "19.09.2014\n",
      "23.09.2014\n",
      "29.09.2014\n",
      "30.09.2014\n",
      "02.10.2014\n",
      "03.10.2014\n",
      "08.10.2014\n",
      "10.10.2014\n",
      "15.10.2014\n",
      "21.10.2014\n",
      "22.10.2014\n",
      "23.10.2014\n",
      "27.10.2014\n",
      "30.10.2014\n",
      "04.11.2014\n",
      "06.11.2014\n",
      "10.11.2014\n",
      "14.11.2014\n",
      "18.11.2014\n",
      "20.11.2014\n",
      "21.11.2014\n",
      "26.11.2014\n",
      "28.11.2014\n",
      "02.12.2014\n",
      "08.12.2014\n",
      "09.12.2014\n",
      "11.12.2014\n",
      "15.12.2014\n",
      "16.12.2014\n",
      "17.12.2014\n",
      "19.12.2014\n",
      "25.12.2014\n",
      "29.12.2014\n",
      "01.01.2015\n",
      "02.01.2015\n",
      "06.01.2015\n",
      "09.01.2015\n",
      "12.01.2015\n",
      "13.01.2015\n",
      "14.01.2015\n",
      "20.01.2015\n",
      "21.01.2015\n",
      "29.01.2015\n",
      "02.02.2015\n",
      "03.02.2015\n",
      "04.02.2015\n",
      "05.02.2015\n",
      "09.02.2015\n",
      "11.02.2015\n",
      "12.02.2015\n",
      "18.02.2015\n",
      "23.02.2015\n",
      "27.02.2015\n",
      "02.03.2015\n",
      "04.03.2015\n",
      "05.03.2015\n",
      "09.03.2015\n",
      "10.03.2015\n",
      "11.03.2015\n",
      "16.03.2015\n",
      "17.03.2015\n",
      "18.03.2015\n",
      "20.03.2015\n",
      "24.03.2015\n",
      "27.03.2015\n",
      "30.03.2015\n",
      "31.03.2015\n",
      "02.04.2015\n",
      "03.04.2015\n",
      "07.04.2015\n",
      "08.04.2015\n",
      "16.04.2015\n",
      "17.04.2015\n",
      "20.04.2015\n",
      "21.04.2015\n",
      "30.04.2015\n",
      "04.05.2015\n",
      "05.05.2015\n",
      "06.05.2015\n",
      "07.05.2015\n",
      "11.05.2015\n",
      "14.05.2015\n",
      "21.05.2015\n",
      "22.05.2015\n",
      "26.05.2015\n",
      "27.05.2015\n",
      "28.05.2015\n",
      "03.06.2015\n",
      "04.06.2015\n",
      "10.06.2015\n",
      "11.06.2015\n",
      "22.06.2015\n",
      "23.06.2015\n",
      "24.06.2015\n",
      "25.06.2015\n",
      "29.06.2015\n",
      "07.07.2015\n",
      "08.07.2015\n",
      "14.07.2015\n",
      "16.07.2015\n",
      "20.07.2015\n",
      "21.07.2015\n",
      "24.07.2015\n",
      "28.07.2015\n",
      "30.07.2015\n",
      "31.07.2015\n",
      "04.08.2015\n",
      "05.08.2015\n",
      "07.08.2015\n",
      "11.08.2015\n",
      "14.08.2015\n",
      "17.08.2015\n",
      "18.08.2015\n",
      "19.08.2015\n",
      "20.08.2015\n",
      "21.08.2015\n",
      "24.08.2015\n",
      "31.08.2015\n",
      "01.09.2015\n",
      "08.09.2015\n",
      "11.09.2015\n",
      "15.09.2015\n",
      "17.09.2015\n",
      "18.09.2015\n",
      "28.09.2015\n",
      "01.10.2015\n",
      "08.10.2015\n",
      "19.10.2015\n",
      "21.10.2015\n",
      "23.10.2015\n",
      "26.10.2015\n",
      "30.10.2015\n",
      "02.11.2015\n",
      "04.11.2015\n",
      "05.11.2015\n",
      "09.11.2015\n",
      "11.11.2015\n",
      "12.11.2015\n",
      "13.11.2015\n",
      "16.11.2015\n",
      "19.11.2015\n",
      "20.11.2015\n",
      "23.11.2015\n",
      "25.11.2015\n",
      "27.11.2015\n",
      "03.12.2015\n",
      "07.12.2015\n",
      "09.12.2015\n",
      "10.12.2015\n",
      "15.12.2015\n",
      "17.12.2015\n",
      "18.12.2015\n",
      "21.12.2015\n",
      "23.12.2015\n",
      "24.12.2015\n",
      "25.12.2015\n",
      "31.12.2015\n",
      "12.01.2016\n",
      "13.01.2016\n",
      "15.01.2016\n",
      "19.01.2016\n",
      "20.01.2016\n",
      "25.01.2016\n",
      "26.01.2016\n",
      "27.01.2016\n",
      "28.01.2016\n",
      "01.02.2016\n",
      "02.02.2016\n",
      "03.02.2016\n",
      "04.02.2016\n",
      "05.02.2016\n",
      "10.02.2016\n",
      "12.02.2016\n",
      "16.02.2016\n",
      "18.02.2016\n",
      "22.02.2016\n",
      "23.02.2016\n",
      "25.02.2016\n",
      "26.02.2016\n",
      "04.03.2016\n",
      "07.03.2016\n",
      "09.03.2016\n",
      "11.03.2016\n",
      "16.03.2016\n",
      "23.03.2016\n",
      "28.03.2016\n",
      "30.03.2016\n",
      "31.03.2016\n",
      "01.04.2016\n",
      "04.04.2016\n",
      "05.04.2016\n",
      "08.04.2016\n",
      "11.04.2016\n",
      "15.04.2016\n",
      "19.04.2016\n",
      "20.04.2016\n",
      "22.04.2016\n",
      "25.04.2016\n",
      "26.04.2016\n",
      "29.04.2016\n",
      "04.05.2016\n",
      "06.05.2016\n",
      "09.05.2016\n",
      "18.05.2016\n",
      "20.05.2016\n",
      "26.05.2016\n",
      "31.05.2016\n",
      "01.06.2016\n",
      "02.06.2016\n",
      "03.06.2016\n",
      "06.06.2016\n",
      "14.06.2016\n",
      "17.06.2016\n",
      "20.06.2016\n",
      "23.06.2016\n",
      "29.06.2016\n",
      "30.06.2016\n",
      "01.07.2016\n",
      "04.07.2016\n",
      "12.07.2016\n",
      "14.07.2016\n",
      "19.07.2016\n",
      "20.07.2016\n",
      "21.07.2016\n",
      "22.07.2016\n",
      "25.07.2016\n",
      "27.07.2016\n",
      "28.07.2016\n",
      "08.08.2016\n",
      "09.08.2016\n",
      "19.08.2016\n",
      "22.08.2016\n",
      "23.08.2016\n",
      "26.08.2016\n",
      "31.08.2016\n",
      "02.09.2016\n",
      "06.09.2016\n",
      "07.09.2016\n",
      "21.09.2016\n",
      "22.09.2016\n",
      "03.10.2016\n",
      "07.10.2016\n",
      "11.10.2016\n",
      "13.10.2016\n",
      "14.10.2016\n",
      "19.10.2016\n",
      "24.10.2016\n",
      "25.10.2016\n",
      "27.10.2016\n",
      "28.10.2016\n",
      "31.10.2016\n",
      "03.11.2016\n",
      "07.11.2016\n",
      "08.11.2016\n",
      "11.11.2016\n",
      "14.11.2016\n",
      "16.11.2016\n",
      "17.11.2016\n",
      "18.11.2016\n",
      "21.11.2016\n",
      "23.11.2016\n",
      "25.11.2016\n",
      "01.12.2016\n",
      "02.12.2016\n",
      "05.12.2016\n",
      "06.12.2016\n",
      "07.12.2016\n",
      "09.12.2016\n",
      "12.12.2016\n",
      "14.12.2016\n",
      "16.12.2016\n",
      "20.12.2016\n",
      "29.12.2016\n",
      "30.12.2016\n",
      "03.01.2017\n",
      "04.01.2017\n",
      "09.01.2017\n",
      "11.01.2017\n",
      "13.01.2017\n",
      "16.01.2017\n",
      "17.01.2017\n",
      "18.01.2017\n",
      "20.01.2017\n",
      "24.01.2017\n",
      "26.01.2017\n",
      "27.01.2017\n",
      "30.01.2017\n",
      "01.02.2017\n",
      "03.02.2017\n",
      "06.02.2017\n",
      "08.02.2017\n",
      "09.02.2017\n",
      "13.02.2017\n",
      "16.02.2017\n",
      "20.02.2017\n",
      "27.02.2017\n",
      "06.03.2017\n",
      "07.03.2017\n",
      "10.03.2017\n",
      "13.03.2017\n",
      "15.03.2017\n",
      "16.03.2017\n",
      "17.03.2017\n",
      "20.03.2017\n",
      "21.03.2017\n",
      "23.03.2017\n",
      "03.04.2017\n",
      "05.04.2017\n",
      "10.04.2017\n",
      "12.04.2017\n",
      "13.04.2017\n",
      "14.04.2017\n",
      "17.04.2017\n",
      "19.04.2017\n",
      "20.04.2017\n",
      "21.04.2017\n",
      "25.04.2017\n",
      "27.04.2017\n",
      "03.05.2017\n",
      "08.05.2017\n",
      "12.05.2017\n",
      "15.05.2017\n",
      "16.05.2017\n",
      "18.05.2017\n",
      "24.05.2017\n",
      "29.05.2017\n",
      "31.05.2017\n",
      "02.06.2017\n",
      "06.06.2017\n",
      "08.06.2017\n",
      "13.06.2017\n",
      "15.06.2017\n",
      "16.06.2017\n",
      "19.06.2017\n",
      "21.06.2017\n",
      "23.06.2017\n",
      "03.07.2017\n",
      "10.07.2017\n",
      "11.07.2017\n",
      "13.07.2017\n",
      "14.07.2017\n",
      "17.07.2017\n",
      "19.07.2017\n",
      "20.07.2017\n",
      "21.07.2017\n",
      "24.07.2017\n",
      "26.07.2017\n",
      "27.07.2017\n",
      "28.07.2017\n",
      "31.07.2017\n",
      "01.08.2017\n",
      "03.08.2017\n",
      "07.08.2017\n",
      "16.08.2017\n",
      "21.08.2017\n",
      "22.08.2017\n",
      "31.08.2017\n",
      "07.09.2017\n",
      "08.09.2017\n",
      "11.09.2017\n",
      "13.09.2017\n",
      "15.09.2017\n",
      "22.09.2017\n",
      "25.09.2017\n",
      "26.09.2017\n",
      "27.09.2017\n",
      "04.10.2017\n",
      "06.10.2017\n",
      "09.10.2017\n",
      "10.10.2017\n",
      "13.10.2017\n",
      "19.10.2017\n",
      "23.10.2017\n",
      "25.10.2017\n",
      "27.10.2017\n",
      "30.10.2017\n",
      "31.10.2017\n",
      "01.11.2017\n",
      "02.11.2017\n",
      "03.11.2017\n",
      "06.11.2017\n",
      "08.11.2017\n",
      "09.11.2017\n",
      "14.11.2017\n",
      "21.11.2017\n",
      "22.11.2017\n",
      "23.11.2017\n",
      "24.11.2017\n",
      "30.11.2017\n",
      "05.12.2017\n",
      "08.12.2017\n",
      "15.12.2017\n",
      "18.12.2017\n",
      "19.12.2017\n",
      "21.12.2017\n",
      "22.12.2017\n",
      "25.12.2017\n",
      "27.12.2017\n",
      "29.12.2017\n",
      "05.01.2018\n",
      "08.01.2018\n",
      "09.01.2018\n",
      "12.01.2018\n",
      "16.01.2018\n",
      "25.01.2018\n",
      "26.01.2018\n",
      "31.01.2018\n",
      "08.02.2018\n",
      "09.02.2018\n",
      "12.02.2018\n",
      "13.02.2018\n",
      "14.02.2018\n",
      "16.02.2018\n",
      "19.02.2018\n",
      "21.02.2018\n",
      "23.02.2018\n",
      "28.02.2018\n",
      "01.03.2018\n",
      "05.03.2018\n",
      "06.03.2018\n",
      "08.03.2018\n",
      "09.03.2018\n",
      "12.03.2018\n",
      "14.03.2018\n",
      "16.03.2018\n",
      "20.03.2018\n",
      "21.03.2018\n",
      "22.03.2018\n",
      "26.03.2018\n",
      "27.03.2018\n",
      "29.03.2018\n",
      "30.03.2018\n",
      "04.04.2018\n",
      "06.04.2018\n",
      "11.04.2018\n",
      "13.04.2018\n",
      "17.04.2018\n",
      "18.04.2018\n",
      "19.04.2018\n",
      "20.04.2018\n",
      "24.04.2018\n",
      "25.04.2018\n",
      "26.04.2018\n",
      "27.04.2018\n",
      "02.05.2018\n",
      "03.05.2018\n",
      "08.05.2018\n",
      "09.05.2018\n",
      "10.05.2018\n",
      "11.05.2018\n",
      "16.05.2018\n",
      "23.05.2018\n",
      "24.05.2018\n",
      "25.05.2018\n",
      "04.06.2018\n",
      "07.06.2018\n",
      "08.06.2018\n",
      "11.06.2018\n",
      "21.06.2018\n",
      "22.06.2018\n",
      "26.06.2018\n",
      "27.06.2018\n",
      "28.06.2018\n",
      "05.07.2018\n",
      "06.07.2018\n",
      "09.07.2018\n",
      "13.07.2018\n",
      "17.07.2018\n",
      "19.07.2018\n",
      "20.07.2018\n",
      "23.07.2018\n",
      "25.07.2018\n",
      "30.07.2018\n",
      "31.07.2018\n",
      "01.08.2018\n",
      "02.08.2018\n",
      "03.08.2018\n",
      "07.08.2018\n",
      "08.08.2018\n",
      "13.08.2018\n",
      "14.08.2018\n",
      "28.08.2018\n",
      "29.08.2018\n",
      "31.08.2018\n",
      "04.09.2018\n",
      "06.09.2018\n",
      "07.09.2018\n",
      "11.09.2018\n",
      "12.09.2018\n",
      "13.09.2018\n",
      "18.09.2018\n",
      "19.09.2018\n",
      "20.09.2018\n",
      "24.09.2018\n",
      "26.09.2018\n",
      "01.10.2018\n",
      "09.10.2018\n",
      "10.10.2018\n",
      "15.10.2018\n",
      "24.10.2018\n",
      "26.10.2018\n",
      "05.11.2018\n",
      "09.11.2018\n",
      "12.11.2018\n",
      "19.11.2018\n",
      "20.11.2018\n",
      "22.11.2018\n",
      "26.11.2018\n",
      "28.11.2018\n",
      "29.11.2018\n",
      "03.12.2018\n",
      "05.12.2018\n",
      "07.12.2018\n",
      "11.12.2018\n",
      "13.12.2018\n",
      "14.12.2018\n",
      "18.12.2018\n",
      "19.12.2018\n",
      "20.12.2018\n",
      "21.12.2018\n",
      "24.12.2018\n",
      "26.12.2018\n",
      "04.01.2019\n",
      "07.01.2019\n",
      "09.01.2019\n",
      "15.01.2019\n",
      "16.01.2019\n",
      "17.01.2019\n",
      "21.01.2019\n",
      "23.01.2019\n",
      "24.01.2019\n",
      "25.01.2019\n",
      "30.01.2019\n",
      "31.01.2019\n",
      "01.02.2019\n",
      "05.02.2019\n",
      "06.02.2019\n",
      "15.02.2019\n",
      "19.02.2019\n",
      "21.02.2019\n",
      "25.02.2019\n",
      "26.02.2019\n",
      "27.02.2019\n",
      "05.03.2019\n",
      "08.03.2019\n",
      "11.03.2019\n",
      "12.03.2019\n",
      "18.03.2019\n",
      "19.03.2019\n",
      "25.03.2019\n",
      "28.03.2019\n",
      "29.03.2019\n",
      "02.04.2019\n",
      "05.04.2019\n",
      "10.04.2019\n",
      "12.04.2019\n",
      "16.04.2019\n",
      "18.04.2019\n",
      "19.04.2019\n",
      "24.04.2019\n",
      "30.04.2019\n",
      "02.05.2019\n",
      "06.05.2019\n",
      "09.05.2019\n",
      "10.05.2019\n",
      "14.05.2019\n",
      "15.05.2019\n",
      "17.05.2019\n",
      "21.05.2019\n",
      "27.05.2019\n",
      "30.05.2019\n",
      "11.06.2019\n",
      "13.06.2019\n",
      "14.06.2019\n",
      "26.06.2019\n",
      "01.07.2019\n",
      "04.07.2019\n",
      "09.07.2019\n",
      "10.07.2019\n",
      "16.07.2019\n",
      "17.07.2019\n",
      "19.07.2019\n",
      "23.07.2019\n",
      "25.07.2019\n",
      "29.07.2019\n",
      "31.07.2019\n",
      "02.08.2019\n",
      "06.08.2019\n",
      "07.08.2019\n",
      "16.08.2019\n",
      "23.08.2019\n",
      "26.08.2019\n",
      "28.08.2019\n",
      "29.08.2019\n",
      "02.09.2019\n",
      "03.09.2019\n",
      "10.09.2019\n",
      "12.09.2019\n",
      "16.09.2019\n",
      "24.09.2019\n",
      "25.09.2019\n",
      "27.09.2019\n",
      "30.09.2019\n",
      "02.10.2019\n",
      "07.10.2019\n",
      "08.10.2019\n",
      "09.10.2019\n",
      "10.10.2019\n",
      "15.10.2019\n",
      "18.10.2019\n",
      "25.10.2019\n",
      "30.10.2019\n",
      "04.11.2019\n",
      "08.11.2019\n",
      "11.11.2019\n",
      "12.11.2019\n",
      "13.11.2019\n",
      "14.11.2019\n",
      "19.11.2019\n",
      "20.11.2019\n",
      "22.11.2019\n",
      "26.11.2019\n",
      "28.11.2019\n",
      "02.12.2019\n",
      "03.12.2019\n",
      "04.12.2019\n",
      "13.12.2019\n",
      "17.12.2019\n",
      "20.12.2019\n",
      "23.12.2019\n",
      "24.12.2019\n",
      "25.12.2019\n",
      "27.12.2019\n",
      "30.12.2019\n",
      "02.01.2020\n",
      "03.01.2020\n",
      "06.01.2020\n",
      "07.01.2020\n",
      "08.01.2020\n",
      "09.01.2020\n",
      "10.01.2020\n",
      "14.01.2020\n",
      "20.01.2020\n",
      "21.01.2020\n",
      "23.01.2020\n",
      "24.01.2020\n",
      "28.01.2020\n",
      "30.01.2020\n",
      "31.01.2020\n",
      "03.02.2020\n",
      "06.02.2020\n",
      "07.02.2020\n",
      "10.02.2020\n",
      "12.02.2020\n",
      "13.02.2020\n",
      "17.02.2020\n",
      "20.02.2020\n",
      "25.02.2020\n",
      "28.02.2020\n",
      "03.03.2020\n",
      "10.03.2020\n",
      "13.03.2020\n",
      "17.03.2020\n",
      "20.03.2020\n",
      "23.03.2020\n",
      "25.03.2020\n",
      "30.03.2020\n",
      "02.04.2020\n",
      "06.04.2020\n",
      "07.04.2020\n",
      "08.04.2020\n",
      "09.04.2020\n",
      "13.04.2020\n",
      "14.04.2020\n",
      "16.04.2020\n",
      "17.04.2020\n",
      "22.04.2020\n",
      "27.04.2020\n",
      "30.04.2020\n",
      "05.05.2020\n",
      "11.05.2020\n",
      "13.05.2020\n",
      "15.05.2020\n",
      "18.05.2020\n",
      "21.05.2020\n",
      "02.06.2020\n",
      "03.06.2020\n",
      "04.06.2020\n",
      "08.06.2020\n",
      "10.06.2020\n",
      "15.06.2020\n",
      "16.06.2020\n",
      "18.06.2020\n",
      "23.06.2020\n",
      "24.06.2020\n",
      "25.06.2020\n",
      "03.07.2020\n",
      "06.07.2020\n",
      "07.07.2020\n",
      "10.07.2020\n",
      "13.07.2020\n",
      "14.07.2020\n",
      "17.07.2020\n",
      "20.07.2020\n",
      "21.07.2020\n",
      "22.07.2020\n",
      "23.07.2020\n",
      "24.07.2020\n",
      "27.07.2020\n",
      "28.07.2020\n",
      "30.07.2020\n",
      "06.08.2020\n",
      "07.08.2020\n",
      "10.08.2020\n",
      "11.08.2020\n",
      "13.08.2020\n",
      "17.08.2020\n",
      "19.08.2020\n",
      "26.08.2020\n",
      "28.08.2020\n",
      "01.09.2020\n",
      "02.09.2020\n",
      "08.09.2020\n",
      "09.09.2020\n",
      "10.09.2020\n",
      "11.09.2020\n",
      "14.09.2020\n",
      "15.09.2020\n",
      "18.09.2020\n",
      "22.09.2020\n",
      "23.09.2020\n",
      "24.09.2020\n",
      "29.09.2020\n",
      "01.10.2020\n",
      "07.10.2020\n",
      "09.10.2020\n",
      "12.10.2020\n",
      "13.10.2020\n",
      "15.10.2020\n",
      "16.10.2020\n",
      "19.10.2020\n",
      "20.10.2020\n",
      "21.10.2020\n",
      "23.10.2020\n",
      "26.10.2020\n",
      "30.10.2020\n",
      "02.11.2020\n",
      "03.11.2020\n",
      "04.11.2020\n",
      "06.11.2020\n",
      "10.11.2020\n",
      "13.11.2020\n",
      "17.11.2020\n",
      "19.11.2020\n",
      "26.11.2020\n",
      "30.11.2020\n",
      "01.12.2020\n",
      "07.12.2020\n",
      "09.12.2020\n",
      "11.12.2020\n",
      "16.12.2020\n",
      "17.12.2020\n",
      "18.12.2020\n",
      "21.12.2020\n",
      "22.12.2020\n",
      "24.12.2020\n",
      "25.12.2020\n",
      "28.12.2020\n",
      "30.12.2020\n",
      "31.12.2020\n",
      "14.01.2021\n",
      "15.01.2021\n",
      "21.01.2021\n",
      "22.01.2021\n",
      "25.01.2021\n",
      "27.01.2021\n",
      "28.01.2021\n",
      "29.01.2021\n",
      "01.02.2021\n",
      "03.02.2021\n",
      "04.02.2021\n",
      "05.02.2021\n",
      "10.02.2021\n",
      "12.02.2021\n",
      "16.02.2021\n",
      "26.02.2021\n",
      "01.03.2021\n",
      "03.03.2021\n",
      "04.03.2021\n",
      "05.03.2021\n",
      "08.03.2021\n",
      "11.03.2021\n",
      "12.03.2021\n",
      "18.03.2021\n",
      "23.03.2021\n",
      "24.03.2021\n",
      "01.04.2021\n",
      "06.04.2021\n",
      "07.04.2021\n",
      "08.04.2021\n",
      "13.04.2021\n",
      "14.04.2021\n",
      "15.04.2021\n",
      "22.04.2021\n",
      "27.04.2021\n",
      "28.04.2021\n",
      "29.04.2021\n",
      "30.04.2021\n",
      "03.05.2021\n",
      "04.05.2021\n",
      "05.05.2021\n",
      "06.05.2021\n",
      "07.05.2021\n",
      "10.05.2021\n",
      "12.05.2021\n",
      "17.05.2021\n",
      "18.05.2021\n",
      "21.05.2021\n",
      "24.05.2021\n",
      "25.05.2021\n",
      "26.05.2021\n",
      "31.05.2021\n",
      "01.06.2021\n",
      "04.06.2021\n",
      "07.06.2021\n",
      "08.06.2021\n",
      "09.06.2021\n",
      "10.06.2021\n",
      "11.06.2021\n",
      "15.06.2021\n",
      "17.06.2021\n",
      "18.06.2021\n",
      "22.06.2021\n",
      "23.06.2021\n",
      "24.06.2021\n",
      "25.06.2021\n",
      "02.07.2021\n",
      "06.07.2021\n",
      "08.07.2021\n",
      "09.07.2021\n",
      "12.07.2021\n",
      "13.07.2021\n",
      "14.07.2021\n",
      "19.07.2021\n",
      "30.07.2021\n",
      "09.08.2021\n",
      "10.08.2021\n",
      "11.08.2021\n",
      "18.08.2021\n",
      "19.08.2021\n",
      "20.08.2021\n",
      "23.08.2021\n",
      "25.08.2021\n",
      "31.08.2021\n",
      "01.09.2021\n",
      "03.09.2021\n",
      "06.09.2021\n",
      "14.09.2021\n",
      "16.09.2021\n",
      "21.09.2021\n",
      "24.09.2021\n",
      "27.09.2021\n",
      "30.09.2021\n",
      "01.10.2021\n",
      "04.10.2021\n",
      "07.10.2021\n",
      "14.10.2021\n",
      "18.10.2021\n",
      "25.10.2021\n",
      "26.10.2021\n",
      "28.10.2021\n",
      "01.11.2021\n",
      "04.11.2021\n",
      "05.11.2021\n",
      "08.11.2021\n",
      "09.11.2021\n",
      "15.11.2021\n",
      "16.11.2021\n",
      "19.11.2021\n",
      "22.11.2021\n",
      "23.11.2021\n",
      "24.11.2021\n",
      "26.11.2021\n",
      "29.11.2021\n",
      "01.12.2021\n",
      "02.12.2021\n",
      "06.12.2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1       0.913700\n",
       "2       0.999000\n",
       "3       1.023800\n",
       "4       0.867700\n",
       "5       0.908100\n",
       "          ...   \n",
       "2654   -0.987399\n",
       "2655   -1.125377\n",
       "2656   -0.748496\n",
       "2657   -1.017789\n",
       "2658   -0.962943\n",
       "Name: yield_spread, Length: 2658, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Yield Spread: -0.513875198645598\n",
      "1193\n"
     ]
    }
   ],
   "source": [
    "# Calculate the yield spread (e.g., 10-year minus 2-year)\n",
    "yield_data['yield_spread'] = yield_data['X3600'] - yield_data['X720']\n",
    "\n",
    "# Find periods of yield curve flattening\n",
    "flattening_periods = []\n",
    "previous_spread = None\n",
    "\n",
    "for index, row in yield_data.iterrows():\n",
    "    current_spread = row['yield_spread']\n",
    "    \n",
    "    if previous_spread is not None:\n",
    "        if current_spread <= previous_spread:\n",
    "            flattening_periods.append(row['Date'])\n",
    "    \n",
    "    previous_spread = current_spread\n",
    "\n",
    "# Print identified flattening periods\n",
    "print(\"Periods of Yield Curve Flattening:\")\n",
    "for period in flattening_periods:\n",
    "    print(period.strftime('%d.%m.%Y'))\n",
    "\n",
    "display(yield_data['yield_spread'])\n",
    "print(\"Mean Yield Spread:\", yield_data['yield_spread'].mean())\n",
    "print((yield_data['yield_spread'] > 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periods of Yield Curve Steepening:\n",
      "06.05.2011\n",
      "09.05.2011\n",
      "11.05.2011\n",
      "12.05.2011\n",
      "16.05.2011\n",
      "25.05.2011\n",
      "26.05.2011\n",
      "27.05.2011\n",
      "30.05.2011\n",
      "31.05.2011\n",
      "07.06.2011\n",
      "08.06.2011\n",
      "14.06.2011\n",
      "16.06.2011\n",
      "17.06.2011\n",
      "24.06.2011\n",
      "29.06.2011\n",
      "30.06.2011\n",
      "01.07.2011\n",
      "05.07.2011\n",
      "06.07.2011\n",
      "07.07.2011\n",
      "11.07.2011\n",
      "14.07.2011\n",
      "15.07.2011\n",
      "19.07.2011\n",
      "20.07.2011\n",
      "21.07.2011\n",
      "22.07.2011\n",
      "26.07.2011\n",
      "28.07.2011\n",
      "05.08.2011\n",
      "09.08.2011\n",
      "10.08.2011\n",
      "11.08.2011\n",
      "15.08.2011\n",
      "17.08.2011\n",
      "25.08.2011\n",
      "26.08.2011\n",
      "02.09.2011\n",
      "06.09.2011\n",
      "07.09.2011\n",
      "09.09.2011\n",
      "12.09.2011\n",
      "13.09.2011\n",
      "16.09.2011\n",
      "21.09.2011\n",
      "22.09.2011\n",
      "26.09.2011\n",
      "28.09.2011\n",
      "30.09.2011\n",
      "04.10.2011\n",
      "11.10.2011\n",
      "12.10.2011\n",
      "13.10.2011\n",
      "17.10.2011\n",
      "25.10.2011\n",
      "27.10.2011\n",
      "28.10.2011\n",
      "01.11.2011\n",
      "10.11.2011\n",
      "14.11.2011\n",
      "16.11.2011\n",
      "18.11.2011\n",
      "24.11.2011\n",
      "01.12.2011\n",
      "02.12.2011\n",
      "05.12.2011\n",
      "06.12.2011\n",
      "07.12.2011\n",
      "14.12.2011\n",
      "16.12.2011\n",
      "23.12.2011\n",
      "27.12.2011\n",
      "02.01.2012\n",
      "09.01.2012\n",
      "11.01.2012\n",
      "12.01.2012\n",
      "13.01.2012\n",
      "18.01.2012\n",
      "19.01.2012\n",
      "24.01.2012\n",
      "25.01.2012\n",
      "26.01.2012\n",
      "27.01.2012\n",
      "30.01.2012\n",
      "31.01.2012\n",
      "01.02.2012\n",
      "03.02.2012\n",
      "10.02.2012\n",
      "13.02.2012\n",
      "17.02.2012\n",
      "20.02.2012\n",
      "21.02.2012\n",
      "22.02.2012\n",
      "28.02.2012\n",
      "01.03.2012\n",
      "05.03.2012\n",
      "08.03.2012\n",
      "09.03.2012\n",
      "13.03.2012\n",
      "15.03.2012\n",
      "16.03.2012\n",
      "21.03.2012\n",
      "26.03.2012\n",
      "27.03.2012\n",
      "28.03.2012\n",
      "29.03.2012\n",
      "30.03.2012\n",
      "02.04.2012\n",
      "04.04.2012\n",
      "05.04.2012\n",
      "06.04.2012\n",
      "20.04.2012\n",
      "24.04.2012\n",
      "08.05.2012\n",
      "14.05.2012\n",
      "16.05.2012\n",
      "17.05.2012\n",
      "18.05.2012\n",
      "21.05.2012\n",
      "23.05.2012\n",
      "30.05.2012\n",
      "31.05.2012\n",
      "01.06.2012\n",
      "04.06.2012\n",
      "06.06.2012\n",
      "07.06.2012\n",
      "12.06.2012\n",
      "13.06.2012\n",
      "14.06.2012\n",
      "20.06.2012\n",
      "21.06.2012\n",
      "22.06.2012\n",
      "25.06.2012\n",
      "26.06.2012\n",
      "27.06.2012\n",
      "28.06.2012\n",
      "02.07.2012\n",
      "03.07.2012\n",
      "04.07.2012\n",
      "05.07.2012\n",
      "06.07.2012\n",
      "10.07.2012\n",
      "16.07.2012\n",
      "20.07.2012\n",
      "23.07.2012\n",
      "26.07.2012\n",
      "27.07.2012\n",
      "30.07.2012\n",
      "31.07.2012\n",
      "01.08.2012\n",
      "02.08.2012\n",
      "03.08.2012\n",
      "06.08.2012\n",
      "10.08.2012\n",
      "13.08.2012\n",
      "15.08.2012\n",
      "16.08.2012\n",
      "22.08.2012\n",
      "27.08.2012\n",
      "28.08.2012\n",
      "29.08.2012\n",
      "31.08.2012\n",
      "04.09.2012\n",
      "05.09.2012\n",
      "06.09.2012\n",
      "07.09.2012\n",
      "10.09.2012\n",
      "11.09.2012\n",
      "13.09.2012\n",
      "14.09.2012\n",
      "19.09.2012\n",
      "21.09.2012\n",
      "28.09.2012\n",
      "01.10.2012\n",
      "02.10.2012\n",
      "03.10.2012\n",
      "05.10.2012\n",
      "09.10.2012\n",
      "11.10.2012\n",
      "12.10.2012\n",
      "15.10.2012\n",
      "16.10.2012\n",
      "17.10.2012\n",
      "19.10.2012\n",
      "22.10.2012\n",
      "23.10.2012\n",
      "24.10.2012\n",
      "30.10.2012\n",
      "02.11.2012\n",
      "07.11.2012\n",
      "08.11.2012\n",
      "09.11.2012\n",
      "12.11.2012\n",
      "13.11.2012\n",
      "15.11.2012\n",
      "21.11.2012\n",
      "27.11.2012\n",
      "28.11.2012\n",
      "05.12.2012\n",
      "06.12.2012\n",
      "07.12.2012\n",
      "10.12.2012\n",
      "21.12.2012\n",
      "27.12.2012\n",
      "28.12.2012\n",
      "02.01.2013\n",
      "04.01.2013\n",
      "07.01.2013\n",
      "09.01.2013\n",
      "10.01.2013\n",
      "14.01.2013\n",
      "18.01.2013\n",
      "21.01.2013\n",
      "22.01.2013\n",
      "23.01.2013\n",
      "24.01.2013\n",
      "28.01.2013\n",
      "29.01.2013\n",
      "30.01.2013\n",
      "01.02.2013\n",
      "04.02.2013\n",
      "05.02.2013\n",
      "06.02.2013\n",
      "07.02.2013\n",
      "11.02.2013\n",
      "19.02.2013\n",
      "20.02.2013\n",
      "21.02.2013\n",
      "05.03.2013\n",
      "06.03.2013\n",
      "07.03.2013\n",
      "08.03.2013\n",
      "11.03.2013\n",
      "13.03.2013\n",
      "21.03.2013\n",
      "28.03.2013\n",
      "29.03.2013\n",
      "02.04.2013\n",
      "03.04.2013\n",
      "08.04.2013\n",
      "10.04.2013\n",
      "16.04.2013\n",
      "17.04.2013\n",
      "18.04.2013\n",
      "25.04.2013\n",
      "26.04.2013\n",
      "29.04.2013\n",
      "03.05.2013\n",
      "06.05.2013\n",
      "09.05.2013\n",
      "13.05.2013\n",
      "14.05.2013\n",
      "15.05.2013\n",
      "16.05.2013\n",
      "22.05.2013\n",
      "27.05.2013\n",
      "28.05.2013\n",
      "04.06.2013\n",
      "07.06.2013\n",
      "10.06.2013\n",
      "11.06.2013\n",
      "14.06.2013\n",
      "17.06.2013\n",
      "19.06.2013\n",
      "24.06.2013\n",
      "28.06.2013\n",
      "02.07.2013\n",
      "04.07.2013\n",
      "08.07.2013\n",
      "11.07.2013\n",
      "16.07.2013\n",
      "19.07.2013\n",
      "24.07.2013\n",
      "25.07.2013\n",
      "29.07.2013\n",
      "30.07.2013\n",
      "31.07.2013\n",
      "02.08.2013\n",
      "07.08.2013\n",
      "20.08.2013\n",
      "21.08.2013\n",
      "22.08.2013\n",
      "23.08.2013\n",
      "27.08.2013\n",
      "28.08.2013\n",
      "29.08.2013\n",
      "02.09.2013\n",
      "04.09.2013\n",
      "06.09.2013\n",
      "09.09.2013\n",
      "10.09.2013\n",
      "11.09.2013\n",
      "12.09.2013\n",
      "13.09.2013\n",
      "16.09.2013\n",
      "17.09.2013\n",
      "18.09.2013\n",
      "20.09.2013\n",
      "24.09.2013\n",
      "02.10.2013\n",
      "07.10.2013\n",
      "08.10.2013\n",
      "10.10.2013\n",
      "21.10.2013\n",
      "22.10.2013\n",
      "23.10.2013\n",
      "24.10.2013\n",
      "25.10.2013\n",
      "28.10.2013\n",
      "31.10.2013\n",
      "12.11.2013\n",
      "21.11.2013\n",
      "25.11.2013\n",
      "26.11.2013\n",
      "27.11.2013\n",
      "28.11.2013\n",
      "03.12.2013\n",
      "04.12.2013\n",
      "10.12.2013\n",
      "11.12.2013\n",
      "12.12.2013\n",
      "16.12.2013\n",
      "17.12.2013\n",
      "19.12.2013\n",
      "24.12.2013\n",
      "26.12.2013\n",
      "31.12.2013\n",
      "02.01.2014\n",
      "07.01.2014\n",
      "09.01.2014\n",
      "14.01.2014\n",
      "15.01.2014\n",
      "16.01.2014\n",
      "23.01.2014\n",
      "04.02.2014\n",
      "05.02.2014\n",
      "11.02.2014\n",
      "12.02.2014\n",
      "13.02.2014\n",
      "14.02.2014\n",
      "18.02.2014\n",
      "19.02.2014\n",
      "20.02.2014\n",
      "25.02.2014\n",
      "26.02.2014\n",
      "28.02.2014\n",
      "03.03.2014\n",
      "04.03.2014\n",
      "05.03.2014\n",
      "07.03.2014\n",
      "10.03.2014\n",
      "12.03.2014\n",
      "13.03.2014\n",
      "18.03.2014\n",
      "19.03.2014\n",
      "20.03.2014\n",
      "21.03.2014\n",
      "27.03.2014\n",
      "01.04.2014\n",
      "07.04.2014\n",
      "08.04.2014\n",
      "09.04.2014\n",
      "14.04.2014\n",
      "15.04.2014\n",
      "21.04.2014\n",
      "22.04.2014\n",
      "25.04.2014\n",
      "28.04.2014\n",
      "30.04.2014\n",
      "06.05.2014\n",
      "07.05.2014\n",
      "08.05.2014\n",
      "12.05.2014\n",
      "14.05.2014\n",
      "22.05.2014\n",
      "23.05.2014\n",
      "26.05.2014\n",
      "27.05.2014\n",
      "28.05.2014\n",
      "30.05.2014\n",
      "03.06.2014\n",
      "04.06.2014\n",
      "09.06.2014\n",
      "10.06.2014\n",
      "11.06.2014\n",
      "12.06.2014\n",
      "20.06.2014\n",
      "24.06.2014\n",
      "25.06.2014\n",
      "26.06.2014\n",
      "27.06.2014\n",
      "30.06.2014\n",
      "02.07.2014\n",
      "04.07.2014\n",
      "08.07.2014\n",
      "09.07.2014\n",
      "10.07.2014\n",
      "11.07.2014\n",
      "15.07.2014\n",
      "16.07.2014\n",
      "18.07.2014\n",
      "23.07.2014\n",
      "25.07.2014\n",
      "07.08.2014\n",
      "11.08.2014\n",
      "14.08.2014\n",
      "15.08.2014\n",
      "18.08.2014\n",
      "20.08.2014\n",
      "21.08.2014\n",
      "22.08.2014\n",
      "26.08.2014\n",
      "28.08.2014\n",
      "02.09.2014\n",
      "05.09.2014\n",
      "09.09.2014\n",
      "11.09.2014\n",
      "15.09.2014\n",
      "16.09.2014\n",
      "18.09.2014\n",
      "22.09.2014\n",
      "24.09.2014\n",
      "25.09.2014\n",
      "26.09.2014\n",
      "01.10.2014\n",
      "09.10.2014\n",
      "13.10.2014\n",
      "14.10.2014\n",
      "16.10.2014\n",
      "17.10.2014\n",
      "20.10.2014\n",
      "24.10.2014\n",
      "28.10.2014\n",
      "31.10.2014\n",
      "03.11.2014\n",
      "05.11.2014\n",
      "07.11.2014\n",
      "11.11.2014\n",
      "12.11.2014\n",
      "13.11.2014\n",
      "17.11.2014\n",
      "19.11.2014\n",
      "24.11.2014\n",
      "25.11.2014\n",
      "27.11.2014\n",
      "01.12.2014\n",
      "03.12.2014\n",
      "04.12.2014\n",
      "05.12.2014\n",
      "10.12.2014\n",
      "12.12.2014\n",
      "18.12.2014\n",
      "22.12.2014\n",
      "23.12.2014\n",
      "24.12.2014\n",
      "26.12.2014\n",
      "30.12.2014\n",
      "31.12.2014\n",
      "05.01.2015\n",
      "07.01.2015\n",
      "08.01.2015\n",
      "15.01.2015\n",
      "16.01.2015\n",
      "19.01.2015\n",
      "22.01.2015\n",
      "23.01.2015\n",
      "26.01.2015\n",
      "27.01.2015\n",
      "28.01.2015\n",
      "30.01.2015\n",
      "06.02.2015\n",
      "10.02.2015\n",
      "13.02.2015\n",
      "16.02.2015\n",
      "17.02.2015\n",
      "19.02.2015\n",
      "20.02.2015\n",
      "24.02.2015\n",
      "25.02.2015\n",
      "26.02.2015\n",
      "03.03.2015\n",
      "06.03.2015\n",
      "12.03.2015\n",
      "13.03.2015\n",
      "19.03.2015\n",
      "23.03.2015\n",
      "25.03.2015\n",
      "26.03.2015\n",
      "01.04.2015\n",
      "06.04.2015\n",
      "09.04.2015\n",
      "10.04.2015\n",
      "13.04.2015\n",
      "14.04.2015\n",
      "15.04.2015\n",
      "22.04.2015\n",
      "24.04.2015\n",
      "27.04.2015\n",
      "28.04.2015\n",
      "29.04.2015\n",
      "08.05.2015\n",
      "12.05.2015\n",
      "13.05.2015\n",
      "15.05.2015\n",
      "18.05.2015\n",
      "20.05.2015\n",
      "25.05.2015\n",
      "29.05.2015\n",
      "01.06.2015\n",
      "02.06.2015\n",
      "05.06.2015\n",
      "08.06.2015\n",
      "09.06.2015\n",
      "12.06.2015\n",
      "15.06.2015\n",
      "16.06.2015\n",
      "17.06.2015\n",
      "18.06.2015\n",
      "19.06.2015\n",
      "26.06.2015\n",
      "30.06.2015\n",
      "01.07.2015\n",
      "02.07.2015\n",
      "03.07.2015\n",
      "06.07.2015\n",
      "09.07.2015\n",
      "10.07.2015\n",
      "13.07.2015\n",
      "15.07.2015\n",
      "22.07.2015\n",
      "23.07.2015\n",
      "27.07.2015\n",
      "29.07.2015\n",
      "03.08.2015\n",
      "06.08.2015\n",
      "10.08.2015\n",
      "12.08.2015\n",
      "13.08.2015\n",
      "25.08.2015\n",
      "26.08.2015\n",
      "27.08.2015\n",
      "28.08.2015\n",
      "02.09.2015\n",
      "03.09.2015\n",
      "04.09.2015\n",
      "07.09.2015\n",
      "09.09.2015\n",
      "10.09.2015\n",
      "14.09.2015\n",
      "16.09.2015\n",
      "21.09.2015\n",
      "22.09.2015\n",
      "23.09.2015\n",
      "29.09.2015\n",
      "30.09.2015\n",
      "02.10.2015\n",
      "05.10.2015\n",
      "06.10.2015\n",
      "07.10.2015\n",
      "09.10.2015\n",
      "12.10.2015\n",
      "13.10.2015\n",
      "14.10.2015\n",
      "15.10.2015\n",
      "16.10.2015\n",
      "20.10.2015\n",
      "22.10.2015\n",
      "27.10.2015\n",
      "28.10.2015\n",
      "03.11.2015\n",
      "06.11.2015\n",
      "10.11.2015\n",
      "17.11.2015\n",
      "18.11.2015\n",
      "24.11.2015\n",
      "26.11.2015\n",
      "30.11.2015\n",
      "01.12.2015\n",
      "02.12.2015\n",
      "04.12.2015\n",
      "08.12.2015\n",
      "11.12.2015\n",
      "14.12.2015\n",
      "16.12.2015\n",
      "22.12.2015\n",
      "28.12.2015\n",
      "29.12.2015\n",
      "30.12.2015\n",
      "04.01.2016\n",
      "05.01.2016\n",
      "06.01.2016\n",
      "07.01.2016\n",
      "08.01.2016\n",
      "11.01.2016\n",
      "14.01.2016\n",
      "18.01.2016\n",
      "21.01.2016\n",
      "22.01.2016\n",
      "29.01.2016\n",
      "08.02.2016\n",
      "09.02.2016\n",
      "11.02.2016\n",
      "15.02.2016\n",
      "17.02.2016\n",
      "19.02.2016\n",
      "24.02.2016\n",
      "29.02.2016\n",
      "01.03.2016\n",
      "02.03.2016\n",
      "03.03.2016\n",
      "08.03.2016\n",
      "10.03.2016\n",
      "14.03.2016\n",
      "15.03.2016\n",
      "17.03.2016\n",
      "18.03.2016\n",
      "21.03.2016\n",
      "22.03.2016\n",
      "24.03.2016\n",
      "25.03.2016\n",
      "29.03.2016\n",
      "06.04.2016\n",
      "07.04.2016\n",
      "12.04.2016\n",
      "13.04.2016\n",
      "14.04.2016\n",
      "18.04.2016\n",
      "21.04.2016\n",
      "27.04.2016\n",
      "28.04.2016\n",
      "02.05.2016\n",
      "03.05.2016\n",
      "05.05.2016\n",
      "10.05.2016\n",
      "11.05.2016\n",
      "12.05.2016\n",
      "13.05.2016\n",
      "16.05.2016\n",
      "17.05.2016\n",
      "23.05.2016\n",
      "24.05.2016\n",
      "25.05.2016\n",
      "27.05.2016\n",
      "30.05.2016\n",
      "07.06.2016\n",
      "08.06.2016\n",
      "09.06.2016\n",
      "10.06.2016\n",
      "13.06.2016\n",
      "15.06.2016\n",
      "16.06.2016\n",
      "21.06.2016\n",
      "22.06.2016\n",
      "24.06.2016\n",
      "27.06.2016\n",
      "28.06.2016\n",
      "08.07.2016\n",
      "11.07.2016\n",
      "13.07.2016\n",
      "15.07.2016\n",
      "18.07.2016\n",
      "26.07.2016\n",
      "29.07.2016\n",
      "01.08.2016\n",
      "02.08.2016\n",
      "03.08.2016\n",
      "04.08.2016\n",
      "05.08.2016\n",
      "10.08.2016\n",
      "11.08.2016\n",
      "12.08.2016\n",
      "15.08.2016\n",
      "16.08.2016\n",
      "17.08.2016\n",
      "18.08.2016\n",
      "24.08.2016\n",
      "25.08.2016\n",
      "29.08.2016\n",
      "01.09.2016\n",
      "05.09.2016\n",
      "08.09.2016\n",
      "09.09.2016\n",
      "16.09.2016\n",
      "19.09.2016\n",
      "20.09.2016\n",
      "23.09.2016\n",
      "26.09.2016\n",
      "27.09.2016\n",
      "28.09.2016\n",
      "29.09.2016\n",
      "30.09.2016\n",
      "04.10.2016\n",
      "05.10.2016\n",
      "06.10.2016\n",
      "10.10.2016\n",
      "12.10.2016\n",
      "17.10.2016\n",
      "18.10.2016\n",
      "20.10.2016\n",
      "21.10.2016\n",
      "26.10.2016\n",
      "01.11.2016\n",
      "02.11.2016\n",
      "04.11.2016\n",
      "09.11.2016\n",
      "10.11.2016\n",
      "15.11.2016\n",
      "22.11.2016\n",
      "24.11.2016\n",
      "28.11.2016\n",
      "29.11.2016\n",
      "30.11.2016\n",
      "08.12.2016\n",
      "13.12.2016\n",
      "15.12.2016\n",
      "19.12.2016\n",
      "21.12.2016\n",
      "22.12.2016\n",
      "23.12.2016\n",
      "26.12.2016\n",
      "27.12.2016\n",
      "28.12.2016\n",
      "02.01.2017\n",
      "05.01.2017\n",
      "06.01.2017\n",
      "10.01.2017\n",
      "12.01.2017\n",
      "19.01.2017\n",
      "23.01.2017\n",
      "25.01.2017\n",
      "31.01.2017\n",
      "02.02.2017\n",
      "07.02.2017\n",
      "10.02.2017\n",
      "14.02.2017\n",
      "15.02.2017\n",
      "17.02.2017\n",
      "21.02.2017\n",
      "22.02.2017\n",
      "23.02.2017\n",
      "24.02.2017\n",
      "28.02.2017\n",
      "01.03.2017\n",
      "02.03.2017\n",
      "03.03.2017\n",
      "08.03.2017\n",
      "09.03.2017\n",
      "14.03.2017\n",
      "22.03.2017\n",
      "24.03.2017\n",
      "27.03.2017\n",
      "28.03.2017\n",
      "29.03.2017\n",
      "30.03.2017\n",
      "31.03.2017\n",
      "04.04.2017\n",
      "06.04.2017\n",
      "07.04.2017\n",
      "11.04.2017\n",
      "18.04.2017\n",
      "24.04.2017\n",
      "26.04.2017\n",
      "28.04.2017\n",
      "02.05.2017\n",
      "04.05.2017\n",
      "05.05.2017\n",
      "09.05.2017\n",
      "10.05.2017\n",
      "11.05.2017\n",
      "17.05.2017\n",
      "22.05.2017\n",
      "23.05.2017\n",
      "25.05.2017\n",
      "26.05.2017\n",
      "30.05.2017\n",
      "01.06.2017\n",
      "05.06.2017\n",
      "07.06.2017\n",
      "09.06.2017\n",
      "12.06.2017\n",
      "14.06.2017\n",
      "20.06.2017\n",
      "22.06.2017\n",
      "28.06.2017\n",
      "29.06.2017\n",
      "30.06.2017\n",
      "04.07.2017\n",
      "05.07.2017\n",
      "06.07.2017\n",
      "07.07.2017\n",
      "12.07.2017\n",
      "18.07.2017\n",
      "25.07.2017\n",
      "02.08.2017\n",
      "04.08.2017\n",
      "08.08.2017\n",
      "09.08.2017\n",
      "10.08.2017\n",
      "11.08.2017\n",
      "14.08.2017\n",
      "15.08.2017\n",
      "17.08.2017\n",
      "18.08.2017\n",
      "23.08.2017\n",
      "24.08.2017\n",
      "25.08.2017\n",
      "28.08.2017\n",
      "29.08.2017\n",
      "05.09.2017\n",
      "06.09.2017\n",
      "12.09.2017\n",
      "14.09.2017\n",
      "18.09.2017\n",
      "19.09.2017\n",
      "20.09.2017\n",
      "21.09.2017\n",
      "28.09.2017\n",
      "29.09.2017\n",
      "02.10.2017\n",
      "03.10.2017\n",
      "05.10.2017\n",
      "11.10.2017\n",
      "12.10.2017\n",
      "16.10.2017\n",
      "17.10.2017\n",
      "18.10.2017\n",
      "20.10.2017\n",
      "24.10.2017\n",
      "26.10.2017\n",
      "07.11.2017\n",
      "10.11.2017\n",
      "13.11.2017\n",
      "15.11.2017\n",
      "16.11.2017\n",
      "17.11.2017\n",
      "20.11.2017\n",
      "27.11.2017\n",
      "28.11.2017\n",
      "29.11.2017\n",
      "01.12.2017\n",
      "04.12.2017\n",
      "06.12.2017\n",
      "07.12.2017\n",
      "11.12.2017\n",
      "12.12.2017\n",
      "13.12.2017\n",
      "14.12.2017\n",
      "20.12.2017\n",
      "26.12.2017\n",
      "28.12.2017\n",
      "02.01.2018\n",
      "03.01.2018\n",
      "04.01.2018\n",
      "10.01.2018\n",
      "11.01.2018\n",
      "15.01.2018\n",
      "17.01.2018\n",
      "19.01.2018\n",
      "22.01.2018\n",
      "23.01.2018\n",
      "24.01.2018\n",
      "29.01.2018\n",
      "30.01.2018\n",
      "01.02.2018\n",
      "02.02.2018\n",
      "05.02.2018\n",
      "06.02.2018\n",
      "07.02.2018\n",
      "15.02.2018\n",
      "20.02.2018\n",
      "22.02.2018\n",
      "26.02.2018\n",
      "27.02.2018\n",
      "02.03.2018\n",
      "07.03.2018\n",
      "13.03.2018\n",
      "15.03.2018\n",
      "19.03.2018\n",
      "23.03.2018\n",
      "28.03.2018\n",
      "02.04.2018\n",
      "03.04.2018\n",
      "05.04.2018\n",
      "09.04.2018\n",
      "10.04.2018\n",
      "12.04.2018\n",
      "16.04.2018\n",
      "30.04.2018\n",
      "04.05.2018\n",
      "07.05.2018\n",
      "14.05.2018\n",
      "15.05.2018\n",
      "17.05.2018\n",
      "18.05.2018\n",
      "21.05.2018\n",
      "22.05.2018\n",
      "28.05.2018\n",
      "29.05.2018\n",
      "30.05.2018\n",
      "31.05.2018\n",
      "01.06.2018\n",
      "05.06.2018\n",
      "06.06.2018\n",
      "12.06.2018\n",
      "13.06.2018\n",
      "14.06.2018\n",
      "18.06.2018\n",
      "19.06.2018\n",
      "20.06.2018\n",
      "25.06.2018\n",
      "29.06.2018\n",
      "02.07.2018\n",
      "03.07.2018\n",
      "04.07.2018\n",
      "10.07.2018\n",
      "11.07.2018\n",
      "12.07.2018\n",
      "16.07.2018\n",
      "18.07.2018\n",
      "24.07.2018\n",
      "26.07.2018\n",
      "27.07.2018\n",
      "06.08.2018\n",
      "09.08.2018\n",
      "10.08.2018\n",
      "15.08.2018\n",
      "16.08.2018\n",
      "17.08.2018\n",
      "20.08.2018\n",
      "27.08.2018\n",
      "03.09.2018\n",
      "05.09.2018\n",
      "10.09.2018\n",
      "14.09.2018\n",
      "17.09.2018\n",
      "21.09.2018\n",
      "25.09.2018\n",
      "27.09.2018\n",
      "28.09.2018\n",
      "02.10.2018\n",
      "03.10.2018\n",
      "04.10.2018\n",
      "05.10.2018\n",
      "08.10.2018\n",
      "11.10.2018\n",
      "12.10.2018\n",
      "16.10.2018\n",
      "17.10.2018\n",
      "18.10.2018\n",
      "19.10.2018\n",
      "22.10.2018\n",
      "23.10.2018\n",
      "25.10.2018\n",
      "30.10.2018\n",
      "31.10.2018\n",
      "01.11.2018\n",
      "02.11.2018\n",
      "06.11.2018\n",
      "07.11.2018\n",
      "08.11.2018\n",
      "13.11.2018\n",
      "14.11.2018\n",
      "15.11.2018\n",
      "16.11.2018\n",
      "21.11.2018\n",
      "23.11.2018\n",
      "27.11.2018\n",
      "30.11.2018\n",
      "04.12.2018\n",
      "06.12.2018\n",
      "10.12.2018\n",
      "12.12.2018\n",
      "17.12.2018\n",
      "25.12.2018\n",
      "27.12.2018\n",
      "28.12.2018\n",
      "31.12.2018\n",
      "02.01.2019\n",
      "03.01.2019\n",
      "08.01.2019\n",
      "10.01.2019\n",
      "11.01.2019\n",
      "14.01.2019\n",
      "18.01.2019\n",
      "22.01.2019\n",
      "28.01.2019\n",
      "29.01.2019\n",
      "04.02.2019\n",
      "07.02.2019\n",
      "08.02.2019\n",
      "11.02.2019\n",
      "12.02.2019\n",
      "13.02.2019\n",
      "14.02.2019\n",
      "18.02.2019\n",
      "20.02.2019\n",
      "22.02.2019\n",
      "28.02.2019\n",
      "01.03.2019\n",
      "04.03.2019\n",
      "06.03.2019\n",
      "07.03.2019\n",
      "13.03.2019\n",
      "14.03.2019\n",
      "15.03.2019\n",
      "20.03.2019\n",
      "21.03.2019\n",
      "22.03.2019\n",
      "26.03.2019\n",
      "27.03.2019\n",
      "01.04.2019\n",
      "03.04.2019\n",
      "04.04.2019\n",
      "08.04.2019\n",
      "09.04.2019\n",
      "11.04.2019\n",
      "15.04.2019\n",
      "17.04.2019\n",
      "22.04.2019\n",
      "25.04.2019\n",
      "26.04.2019\n",
      "29.04.2019\n",
      "03.05.2019\n",
      "07.05.2019\n",
      "08.05.2019\n",
      "13.05.2019\n",
      "16.05.2019\n",
      "20.05.2019\n",
      "22.05.2019\n",
      "23.05.2019\n",
      "24.05.2019\n",
      "28.05.2019\n",
      "29.05.2019\n",
      "31.05.2019\n",
      "03.06.2019\n",
      "07.06.2019\n",
      "10.06.2019\n",
      "12.06.2019\n",
      "17.06.2019\n",
      "18.06.2019\n",
      "19.06.2019\n",
      "20.06.2019\n",
      "21.06.2019\n",
      "24.06.2019\n",
      "25.06.2019\n",
      "27.06.2019\n",
      "28.06.2019\n",
      "02.07.2019\n",
      "03.07.2019\n",
      "05.07.2019\n",
      "08.07.2019\n",
      "11.07.2019\n",
      "12.07.2019\n",
      "18.07.2019\n",
      "22.07.2019\n",
      "24.07.2019\n",
      "26.07.2019\n",
      "30.07.2019\n",
      "01.08.2019\n",
      "05.08.2019\n",
      "08.08.2019\n",
      "09.08.2019\n",
      "15.08.2019\n",
      "19.08.2019\n",
      "20.08.2019\n",
      "21.08.2019\n",
      "22.08.2019\n",
      "27.08.2019\n",
      "04.09.2019\n",
      "05.09.2019\n",
      "06.09.2019\n",
      "09.09.2019\n",
      "11.09.2019\n",
      "13.09.2019\n",
      "17.09.2019\n",
      "18.09.2019\n",
      "19.09.2019\n",
      "20.09.2019\n",
      "23.09.2019\n",
      "26.09.2019\n",
      "01.10.2019\n",
      "03.10.2019\n",
      "04.10.2019\n",
      "11.10.2019\n",
      "14.10.2019\n",
      "16.10.2019\n",
      "17.10.2019\n",
      "21.10.2019\n",
      "22.10.2019\n",
      "23.10.2019\n",
      "24.10.2019\n",
      "28.10.2019\n",
      "31.10.2019\n",
      "01.11.2019\n",
      "05.11.2019\n",
      "06.11.2019\n",
      "07.11.2019\n",
      "15.11.2019\n",
      "18.11.2019\n",
      "21.11.2019\n",
      "25.11.2019\n",
      "27.11.2019\n",
      "29.11.2019\n",
      "05.12.2019\n",
      "06.12.2019\n",
      "09.12.2019\n",
      "10.12.2019\n",
      "11.12.2019\n",
      "12.12.2019\n",
      "16.12.2019\n",
      "18.12.2019\n",
      "19.12.2019\n",
      "26.12.2019\n",
      "31.12.2019\n",
      "13.01.2020\n",
      "15.01.2020\n",
      "16.01.2020\n",
      "17.01.2020\n",
      "22.01.2020\n",
      "27.01.2020\n",
      "29.01.2020\n",
      "04.02.2020\n",
      "05.02.2020\n",
      "11.02.2020\n",
      "14.02.2020\n",
      "18.02.2020\n",
      "19.02.2020\n",
      "21.02.2020\n",
      "24.02.2020\n",
      "26.02.2020\n",
      "27.02.2020\n",
      "02.03.2020\n",
      "04.03.2020\n",
      "05.03.2020\n",
      "06.03.2020\n",
      "09.03.2020\n",
      "11.03.2020\n",
      "12.03.2020\n",
      "16.03.2020\n",
      "18.03.2020\n",
      "19.03.2020\n",
      "24.03.2020\n",
      "26.03.2020\n",
      "27.03.2020\n",
      "31.03.2020\n",
      "01.04.2020\n",
      "03.04.2020\n",
      "10.04.2020\n",
      "15.04.2020\n",
      "20.04.2020\n",
      "21.04.2020\n",
      "24.04.2020\n",
      "28.04.2020\n",
      "29.04.2020\n",
      "04.05.2020\n",
      "06.05.2020\n",
      "07.05.2020\n",
      "08.05.2020\n",
      "12.05.2020\n",
      "14.05.2020\n",
      "20.05.2020\n",
      "22.05.2020\n",
      "27.05.2020\n",
      "28.05.2020\n",
      "29.05.2020\n",
      "01.06.2020\n",
      "05.06.2020\n",
      "09.06.2020\n",
      "11.06.2020\n",
      "12.06.2020\n",
      "17.06.2020\n",
      "19.06.2020\n",
      "22.06.2020\n",
      "26.06.2020\n",
      "29.06.2020\n",
      "30.06.2020\n",
      "01.07.2020\n",
      "02.07.2020\n",
      "08.07.2020\n",
      "09.07.2020\n",
      "16.07.2020\n",
      "29.07.2020\n",
      "04.08.2020\n",
      "05.08.2020\n",
      "12.08.2020\n",
      "14.08.2020\n",
      "18.08.2020\n",
      "20.08.2020\n",
      "21.08.2020\n",
      "24.08.2020\n",
      "25.08.2020\n",
      "27.08.2020\n",
      "31.08.2020\n",
      "03.09.2020\n",
      "04.09.2020\n",
      "07.09.2020\n",
      "16.09.2020\n",
      "17.09.2020\n",
      "21.09.2020\n",
      "25.09.2020\n",
      "28.09.2020\n",
      "30.09.2020\n",
      "02.10.2020\n",
      "05.10.2020\n",
      "06.10.2020\n",
      "08.10.2020\n",
      "14.10.2020\n",
      "22.10.2020\n",
      "27.10.2020\n",
      "28.10.2020\n",
      "05.11.2020\n",
      "09.11.2020\n",
      "11.11.2020\n",
      "12.11.2020\n",
      "16.11.2020\n",
      "18.11.2020\n",
      "20.11.2020\n",
      "23.11.2020\n",
      "24.11.2020\n",
      "25.11.2020\n",
      "27.11.2020\n",
      "02.12.2020\n",
      "03.12.2020\n",
      "04.12.2020\n",
      "08.12.2020\n",
      "10.12.2020\n",
      "14.12.2020\n",
      "15.12.2020\n",
      "23.12.2020\n",
      "29.12.2020\n",
      "04.01.2021\n",
      "05.01.2021\n",
      "06.01.2021\n",
      "07.01.2021\n",
      "08.01.2021\n",
      "11.01.2021\n",
      "12.01.2021\n",
      "13.01.2021\n",
      "18.01.2021\n",
      "19.01.2021\n",
      "20.01.2021\n",
      "26.01.2021\n",
      "02.02.2021\n",
      "08.02.2021\n",
      "09.02.2021\n",
      "11.02.2021\n",
      "15.02.2021\n",
      "17.02.2021\n",
      "18.02.2021\n",
      "19.02.2021\n",
      "22.02.2021\n",
      "23.02.2021\n",
      "24.02.2021\n",
      "25.02.2021\n",
      "02.03.2021\n",
      "09.03.2021\n",
      "10.03.2021\n",
      "15.03.2021\n",
      "16.03.2021\n",
      "17.03.2021\n",
      "19.03.2021\n",
      "22.03.2021\n",
      "25.03.2021\n",
      "26.03.2021\n",
      "29.03.2021\n",
      "30.03.2021\n",
      "31.03.2021\n",
      "02.04.2021\n",
      "05.04.2021\n",
      "09.04.2021\n",
      "12.04.2021\n",
      "16.04.2021\n",
      "19.04.2021\n",
      "20.04.2021\n",
      "21.04.2021\n",
      "26.04.2021\n",
      "11.05.2021\n",
      "20.05.2021\n",
      "27.05.2021\n",
      "28.05.2021\n",
      "02.06.2021\n",
      "03.06.2021\n",
      "14.06.2021\n",
      "16.06.2021\n",
      "21.06.2021\n",
      "28.06.2021\n",
      "29.06.2021\n",
      "30.06.2021\n",
      "01.07.2021\n",
      "05.07.2021\n",
      "07.07.2021\n",
      "16.07.2021\n",
      "26.07.2021\n",
      "27.07.2021\n",
      "28.07.2021\n",
      "29.07.2021\n",
      "02.08.2021\n",
      "03.08.2021\n",
      "04.08.2021\n",
      "05.08.2021\n",
      "06.08.2021\n",
      "12.08.2021\n",
      "13.08.2021\n",
      "16.08.2021\n",
      "17.08.2021\n",
      "24.08.2021\n",
      "26.08.2021\n",
      "27.08.2021\n",
      "02.09.2021\n",
      "07.09.2021\n",
      "08.09.2021\n",
      "09.09.2021\n",
      "10.09.2021\n",
      "13.09.2021\n",
      "15.09.2021\n",
      "17.09.2021\n",
      "20.09.2021\n",
      "22.09.2021\n",
      "23.09.2021\n",
      "28.09.2021\n",
      "29.09.2021\n",
      "05.10.2021\n",
      "06.10.2021\n",
      "08.10.2021\n",
      "11.10.2021\n",
      "12.10.2021\n",
      "13.10.2021\n",
      "15.10.2021\n",
      "19.10.2021\n",
      "20.10.2021\n",
      "21.10.2021\n",
      "22.10.2021\n",
      "27.10.2021\n",
      "02.11.2021\n",
      "03.11.2021\n",
      "10.11.2021\n",
      "11.11.2021\n",
      "12.11.2021\n",
      "17.11.2021\n",
      "18.11.2021\n",
      "25.11.2021\n",
      "30.11.2021\n",
      "03.12.2021\n",
      "07.12.2021\n"
     ]
    }
   ],
   "source": [
    "# Find periods of yield curve steepening\n",
    "steepening_periods = []\n",
    "previous_spread = None\n",
    "\n",
    "for index, row in yield_data.iterrows():\n",
    "    current_spread = row['yield_spread']\n",
    "    \n",
    "    if previous_spread is not None:\n",
    "        if current_spread >= previous_spread:\n",
    "            steepening_periods.append(row['Date'])\n",
    "    \n",
    "    previous_spread = current_spread\n",
    "\n",
    "# Print identified steepening periods\n",
    "print(\"Periods of Yield Curve Steepening:\")\n",
    "for period in steepening_periods:\n",
    "    print(period.strftime('%d.%m.%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio for each Principal Component:\n",
      "Year 2013:\n",
      "PC1: 0.4964\n",
      "PC2: 0.3055\n",
      "PC3: 0.1090\n",
      "PC4: 0.0435\n",
      "PC5: 0.0227\n",
      "PC6: 0.0141\n",
      "PC7: 0.0070\n",
      "PC8: 0.0014\n",
      "PC9: 0.0004\n",
      "PC10: 0.0000\n",
      "PC11: 0.0000\n",
      "PC12: 0.0000\n",
      "PC13: 0.0000\n",
      "PC14: 0.0000\n",
      "PC15: 0.0000\n",
      "PC16: 0.0000\n",
      "PC17: 0.0000\n",
      "PC18: 0.0000\n",
      "PC19: 0.0000\n",
      "\n",
      "Year 2018:\n",
      "PC1: 0.4678\n",
      "PC2: 0.2051\n",
      "PC3: 0.1717\n",
      "PC4: 0.0801\n",
      "PC5: 0.0347\n",
      "PC6: 0.0183\n",
      "PC7: 0.0150\n",
      "PC8: 0.0045\n",
      "PC9: 0.0025\n",
      "PC10: 0.0002\n",
      "PC11: 0.0000\n",
      "PC12: 0.0000\n",
      "PC13: 0.0000\n",
      "PC14: 0.0000\n",
      "PC15: 0.0000\n",
      "PC16: 0.0000\n",
      "PC17: 0.0000\n",
      "PC18: 0.0000\n",
      "PC19: 0.0000\n",
      "\n",
      "Year 2019:\n",
      "PC1: 0.4821\n",
      "PC2: 0.1956\n",
      "PC3: 0.1866\n",
      "PC4: 0.0489\n",
      "PC5: 0.0443\n",
      "PC6: 0.0231\n",
      "PC7: 0.0173\n",
      "PC8: 0.0013\n",
      "PC9: 0.0005\n",
      "PC10: 0.0003\n",
      "PC11: 0.0000\n",
      "PC12: 0.0000\n",
      "PC13: 0.0000\n",
      "PC14: 0.0000\n",
      "PC15: 0.0000\n",
      "PC16: 0.0000\n",
      "PC17: 0.0000\n",
      "PC18: 0.0000\n",
      "PC19: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Filter data for each year\n",
    "data_2013 = yield_data[yield_data['Date'].dt.year == 2013].copy()\n",
    "data_2018 = yield_data[yield_data['Date'].dt.year == 2018].copy()\n",
    "data_2019 = yield_data[yield_data['Date'].dt.year == 2019].copy()\n",
    "\n",
    "# Drop non-numeric columns if any\n",
    "data_2013_numeric = data_2013.drop('Date', axis=1)\n",
    "data_2018_numeric = data_2018.drop('Date', axis=1)\n",
    "data_2019_numeric = data_2019.drop('Date', axis=1)\n",
    "\n",
    "# Handle missing values if any\n",
    "data_2013_numeric.dropna(inplace=True)\n",
    "data_2018_numeric.dropna(inplace=True)\n",
    "data_2019_numeric.dropna(inplace=True)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_2013_scaled = scaler.fit_transform(data_2013_numeric)\n",
    "data_2018_scaled = scaler.fit_transform(data_2018_numeric)\n",
    "data_2019_scaled = scaler.fit_transform(data_2019_numeric)\n",
    "\n",
    "# Apply PCA for each year\n",
    "pca_2013 = PCA()\n",
    "pca_2013.fit(data_2013_scaled)\n",
    "pca_2018 = PCA()\n",
    "pca_2018.fit(data_2018_scaled)\n",
    "pca_2019 = PCA()\n",
    "pca_2019.fit(data_2019_scaled)\n",
    "\n",
    "# Get the explained variance ratio for each year\n",
    "explained_variance_ratio_2013 = pca_2013.explained_variance_ratio_\n",
    "explained_variance_ratio_2018 = pca_2018.explained_variance_ratio_\n",
    "explained_variance_ratio_2019 = pca_2019.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio for each principal component for each year\n",
    "print(\"Explained Variance Ratio for each Principal Component:\")\n",
    "print(\"Year 2013:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio_2013):\n",
    "    print(f\"PC{i+1}: {ratio:.4f}\")\n",
    "\n",
    "print(\"\\nYear 2018:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio_2018):\n",
    "    print(f\"PC{i+1}: {ratio:.4f}\")\n",
    "\n",
    "print(\"\\nYear 2019:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio_2019):\n",
    "    print(f\"PC{i+1}: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
